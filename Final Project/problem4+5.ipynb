{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-19T01:11:37.785026Z",
     "start_time": "2025-04-19T01:03:15.585154Z"
    }
   },
   "source": [
    "# Part 4: Advanced Distribution Risk Models and VaR/ES Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import kv\n",
    "from scipy.integrate import quad\n",
    "\n",
    "\n",
    "# First, read and process the portfolio data\n",
    "# Step 1: Load the data\n",
    "daily_prices = pd.read_csv('../Projects/Final Project/DailyPrices.csv')\n",
    "initial_portfolio = pd.read_csv('../Projects/Final Project/initial_portfolio.csv')\n",
    "risk_free = pd.read_csv('../Projects/Final Project/rf.csv')\n",
    "\n",
    "# Convert dates to datetime format\n",
    "daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "risk_free['Date'] = pd.to_datetime(risk_free['Date'])\n",
    "\n",
    "# Step 2: Split data into training (2023) and testing (2024-2025) periods\n",
    "training_data = daily_prices[daily_prices['Date'] <= pd.Timestamp('2023-12-29')]\n",
    "testing_data = daily_prices[daily_prices['Date'] >= pd.Timestamp('2023-12-29')]\n",
    "\n",
    "\n",
    "# Step 3: Calculate returns\n",
    "# Function to calculate daily returns\n",
    "def calculate_returns(prices_df):\n",
    "    returns_df = prices_df.copy()\n",
    "    for column in prices_df.columns:\n",
    "        if column != 'Date':\n",
    "            returns_df[column] = prices_df[column].pct_change()\n",
    "    return returns_df.dropna()\n",
    "\n",
    "\n",
    "# Calculate returns for training and testing periods\n",
    "training_returns = calculate_returns(training_data)\n",
    "testing_returns = calculate_returns(testing_data)\n",
    "\n",
    "\n",
    "# # Get unique portfolio names\n",
    "portfolios = initial_portfolio['Portfolio'].unique().tolist()\n",
    "print(f\"Unique portfolios: {portfolios}\")\n",
    "\n",
    "# Calculate the total value of each portfolio\n",
    "portfolio_values = {}\n",
    "for portfolio in portfolios:\n",
    "    portfolio_holdings = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "    total_value = portfolio_holdings['Holding'].sum()\n",
    "    portfolio_values[portfolio] = total_value\n",
    "\n",
    "# Create the portfolio_weights dictionary with the correct structure\n",
    "portfolio_weights = {}\n",
    "for portfolio in portfolios:\n",
    "    portfolio_weights[portfolio] = {}\n",
    "\n",
    "    # Get holdings for this portfolio\n",
    "    portfolio_holdings = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "\n",
    "    # Calculate total portfolio value\n",
    "    total_value = portfolio_holdings['Holding'].sum()\n",
    "\n",
    "    # Calculate weight for each symbol\n",
    "    for _, row in portfolio_holdings.iterrows():\n",
    "        symbol = row['Symbol']\n",
    "        holding = row['Holding']\n",
    "        weight = holding / total_value if total_value > 0 else 0\n",
    "\n",
    "        portfolio_weights[portfolio][symbol] = {\n",
    "            'weight': weight,\n",
    "            'holding': holding\n",
    "        }\n",
    "\n",
    "print(\"Portfolio weights successfully created.\")\n",
    "\n",
    "class NormalInverseGaussian:\n",
    "    \"\"\"\n",
    "    Custom implementation of the Normal Inverse Gaussian distribution.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha, beta, mu, delta):\n",
    "        # Parameter checks\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"alpha must be positive\")\n",
    "        if abs(beta) >= alpha:\n",
    "            raise ValueError(\"abs(beta) must be less than alpha\")\n",
    "        if delta <= 0:\n",
    "            raise ValueError(\"delta must be positive\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.mu = mu\n",
    "        self.delta = delta\n",
    "        # Derived parameter\n",
    "        self.gamma = np.sqrt(alpha**2 - beta**2)\n",
    "\n",
    "    def pdf(self, x):\n",
    "        \"\"\"Probability density function\"\"\"\n",
    "        alpha, beta, mu, delta = self.alpha, self.beta, self.mu, self.delta\n",
    "        gamma = self.gamma\n",
    "\n",
    "        # Handle array input\n",
    "        if np.isscalar(x):\n",
    "            x = np.array([x])\n",
    "        else:\n",
    "            x = np.asarray(x)\n",
    "\n",
    "        # Calculate components\n",
    "        arg = alpha * np.sqrt(delta**2 + (x - mu)**2)\n",
    "\n",
    "        # Calculate PDF\n",
    "        pdf_values = (alpha * delta * kv(1, arg) *\n",
    "                      np.exp(delta * gamma + beta * (x - mu)) /\n",
    "                      (np.pi * np.sqrt(delta**2 + (x - mu)**2)))\n",
    "\n",
    "        # Handle potential numerical issues\n",
    "        pdf_values = np.maximum(pdf_values, 1e-300)\n",
    "\n",
    "        if len(pdf_values) == 1:\n",
    "            return pdf_values[0]\n",
    "        return pdf_values\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Fit distribution parameters using MLE\"\"\"\n",
    "        data = np.asarray(data)\n",
    "\n",
    "        # Define negative log-likelihood function\n",
    "        def neg_loglikelihood(params):\n",
    "            alpha, beta, mu, delta = params\n",
    "            if alpha <= 0 or delta <= 0 or abs(beta) >= alpha:\n",
    "                return np.inf\n",
    "\n",
    "            try:\n",
    "                model = NormalInverseGaussian(alpha, beta, mu, delta)\n",
    "                pdf_values = model.pdf(data)\n",
    "                # Handle numerical issues\n",
    "                pdf_values = np.maximum(pdf_values, 1e-300)\n",
    "                return -np.sum(np.log(pdf_values))\n",
    "            except:\n",
    "                return np.inf\n",
    "\n",
    "        # Initial parameter estimates\n",
    "        mean = np.mean(data)\n",
    "        var = np.var(data)\n",
    "        skew = stats.skew(data)\n",
    "        kurtosis = stats.kurtosis(data, fisher=False)\n",
    "\n",
    "        # Initial estimates\n",
    "        try:\n",
    "            if kurtosis > 3:  # Must be leptokurtic for NIG\n",
    "                delta_init = 3 * var / (kurtosis - 3)\n",
    "                alpha_init = np.sqrt(3 * kurtosis / (var * (kurtosis - 3)))\n",
    "                beta_init = skew / (var * np.sqrt(kurtosis - 3)) if skew != 0 else 0\n",
    "                mu_init = mean - beta_init * delta_init / np.sqrt(alpha_init**2 - beta_init**2)\n",
    "            else:\n",
    "                # Fallback if kurtosis doesn't meet requirements\n",
    "                delta_init = var\n",
    "                alpha_init = 2.0 / np.sqrt(var)\n",
    "                beta_init = skew / (2.0 * var) if skew != 0 else 0\n",
    "                mu_init = mean\n",
    "        except:\n",
    "            # Simple fallback if moment-based estimates fail\n",
    "            delta_init = np.std(data)\n",
    "            alpha_init = 1.5 / delta_init\n",
    "            beta_init = 0\n",
    "            mu_init = mean\n",
    "\n",
    "        # Ensure alpha > |beta|\n",
    "        if abs(beta_init) >= alpha_init:\n",
    "            alpha_init = abs(beta_init) + 0.1\n",
    "\n",
    "        # Initial parameters\n",
    "        initial_params = [alpha_init, beta_init, mu_init, delta_init]\n",
    "\n",
    "        # Optimize\n",
    "        try:\n",
    "            result = minimize(neg_loglikelihood, initial_params,\n",
    "                             method='Nelder-Mead',\n",
    "                             bounds=[(0.001, None), (None, None), (None, None), (0.001, None)])\n",
    "\n",
    "            if result.success:\n",
    "                alpha, beta, mu, delta = result.x\n",
    "                return alpha, beta, mu, delta\n",
    "            else:\n",
    "                return alpha_init, beta_init, mu_init, delta_init\n",
    "        except:\n",
    "            return alpha_init, beta_init, mu_init, delta_init\n",
    "\n",
    "    def cdf(self, x):\n",
    "        \"\"\"Cumulative distribution function\"\"\"\n",
    "        if np.isscalar(x):\n",
    "            lower_bound = x - 50 * self.delta\n",
    "            result, _ = quad(self.pdf, lower_bound, x)\n",
    "            return result\n",
    "        else:\n",
    "            return np.array([self.cdf(xi) for xi in x])\n",
    "\n",
    "    def ppf(self, q):\n",
    "        \"\"\"Percent point function (inverse CDF)\"\"\"\n",
    "        if np.isscalar(q):\n",
    "            if q <= 0: return -np.inf\n",
    "            if q >= 1: return np.inf\n",
    "\n",
    "            x_min, x_max = self.mu - 50 * self.delta, self.mu + 50 * self.delta\n",
    "\n",
    "            # Expand range if needed\n",
    "            attempts = 0\n",
    "            while attempts < 10:\n",
    "                if self.cdf(x_min) > q:\n",
    "                    x_min -= 50 * self.delta\n",
    "                elif self.cdf(x_max) < q:\n",
    "                    x_max += 50 * self.delta\n",
    "                else:\n",
    "                    break\n",
    "                attempts += 1\n",
    "\n",
    "            # Binary search\n",
    "            for _ in range(50):\n",
    "                x_mid = (x_min + x_max) / 2\n",
    "                cdf_mid = self.cdf(x_mid)\n",
    "\n",
    "                if abs(cdf_mid - q) < 1e-6:\n",
    "                    return x_mid\n",
    "\n",
    "                if cdf_mid < q:\n",
    "                    x_min = x_mid\n",
    "                else:\n",
    "                    x_max = x_mid\n",
    "\n",
    "            return (x_min + x_max) / 2\n",
    "        else:\n",
    "            return np.array([self.ppf(qi) for qi in q])\n",
    "\n",
    "\n",
    "# 2. Fit distributions to pre-holding period data\n",
    "print(\"\\nFitting distributions to pre-holding period stock returns...\")\n",
    "\n",
    "# Use training data for fitting\n",
    "fit_results = {}\n",
    "best_models = {}\n",
    "model_params = {}\n",
    "stock_returns = {}\n",
    "\n",
    "# List of symbols excluding Date\n",
    "symbols = [col for col in training_returns.columns if col not in ['Date', 'rf']]\n",
    "symbols = [s for s in symbols if not s.endswith('_excess')]\n",
    "\n",
    "# Define a function to evaluate model fit using AIC\n",
    "def calculate_aic(log_likelihood, k):\n",
    "    return 2 * k - 2 * log_likelihood\n",
    "\n",
    "# Function to fit all distributions to a stock's returns\n",
    "def fit_distributions(returns):\n",
    "    result = {}\n",
    "\n",
    "    # Filter out any NaN values - Fix for numpy arrays\n",
    "    if isinstance(returns, np.ndarray):\n",
    "        clean_returns = returns[~np.isnan(returns)]\n",
    "    else:\n",
    "        # If it's a pandas Series or DataFrame\n",
    "        clean_returns = returns.dropna()\n",
    "\n",
    "    # 1. Normal distribution\n",
    "    try:\n",
    "        norm_params = stats.norm.fit(clean_returns)\n",
    "        mu, sigma = norm_params\n",
    "        log_likelihood = np.sum(stats.norm.logpdf(clean_returns, mu, sigma))\n",
    "        aic = calculate_aic(log_likelihood, 2)  # 2 parameters: mu, sigma\n",
    "        result['Normal'] = {\n",
    "            'params': norm_params,\n",
    "            'aic': aic,\n",
    "            'dist': stats.norm(*norm_params)\n",
    "        }\n",
    "    except:\n",
    "        result['Normal'] = {'aic': np.inf}\n",
    "\n",
    "    # 2. Generalized T distribution\n",
    "    try:\n",
    "        t_params = stats.t.fit(clean_returns)\n",
    "        log_likelihood = np.sum(stats.t.logpdf(clean_returns, *t_params))\n",
    "        aic = calculate_aic(log_likelihood, 3)  # 3 parameters: df, loc, scale\n",
    "        result['GeneralizedT'] = {\n",
    "            'params': t_params,\n",
    "            'aic': aic,\n",
    "            'dist': stats.t(*t_params)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting GeneralizedT: {e}\")\n",
    "        result['GeneralizedT'] = {'aic': np.inf}\n",
    "\n",
    "    # 3. NIG distribution\n",
    "    try:\n",
    "        nig = NormalInverseGaussian(1, 0, 0, 1)  # Default initialization\n",
    "        alpha, beta, mu, delta = nig.fit(clean_returns)\n",
    "        nig_params = (alpha, beta, mu, delta)\n",
    "        nig_fitted = NormalInverseGaussian(*nig_params)\n",
    "\n",
    "        # Calculate log-likelihood and AIC\n",
    "        pdf_values = nig_fitted.pdf(clean_returns)\n",
    "        pdf_values = np.maximum(pdf_values, 1e-300)  # Avoid log(0)\n",
    "        log_likelihood = np.sum(np.log(pdf_values))\n",
    "        aic = calculate_aic(log_likelihood, 4)  # 4 parameters: alpha, beta, mu, delta\n",
    "\n",
    "        result['NIG'] = {\n",
    "            'params': nig_params,\n",
    "            'aic': aic,\n",
    "            'dist': nig_fitted\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting NIG: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()  # Print the full traceback for debugging\n",
    "        result['NIG'] = {'aic': np.inf}\n",
    "\n",
    "\n",
    "# 4. Skew Normal\n",
    "    try:\n",
    "        skewnorm_params = stats.skewnorm.fit(clean_returns)\n",
    "        log_likelihood = np.sum(stats.skewnorm.logpdf(clean_returns, *skewnorm_params))\n",
    "        aic = calculate_aic(log_likelihood, 3)  # 3 parameters: a, loc, scale\n",
    "        result['SkewNormal'] = {\n",
    "            'params': skewnorm_params,\n",
    "            'aic': aic,\n",
    "            'dist': stats.skewnorm(*skewnorm_params)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting SkewNormal: {e}\")\n",
    "        result['SkewNormal'] = {'aic': np.inf}\n",
    "\n",
    "    # Find best model based on AIC\n",
    "    best_model = min(result.items(), key=lambda x: x[1]['aic'])[0]\n",
    "\n",
    "    return result, best_model\n",
    "\n",
    "# Fit distributions for each stock\n",
    "for symbol in symbols:\n",
    "    # Extract training period returns\n",
    "    returns = training_returns[symbol].values\n",
    "    stock_returns[symbol] = returns\n",
    "\n",
    "    # Fit all distributions and find the best one\n",
    "    try:\n",
    "        fit_results[symbol], best_models[symbol] = fit_distributions(returns)\n",
    "        model_params[symbol] = fit_results[symbol][best_models[symbol]]['params']\n",
    "        # print(f\"{symbol}: Best fit model is {best_models[symbol]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting distributions for {symbol}: {e}\")\n",
    "        best_models[symbol] = \"Normal\"  # Default to normal if fitting fails\n",
    "        model_params[symbol] = stats.norm.fit(returns)\n",
    "\n",
    "# Report best fit models and parameters\n",
    "print(\"\\nBest Fit Distribution Models and Parameters:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Symbol':<8} {'Best Model':<15} {'Parameters'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for symbol in symbols:\n",
    "    params = model_params[symbol]\n",
    "    rounded_params = tuple([round(float(p), 8) for p in params])\n",
    "    print(f\"{symbol:<8} {best_models[symbol]:<15} {rounded_params}\")\n",
    "\n",
    "# 3. Calculate VaR and ES using Gaussian Copula with fitted marginals\n",
    "print(\"\\nCalculating VaR and ES using Gaussian Copula with fitted marginals...\")\n",
    "\n",
    "# Function to calculate portfolio VaR and ES\n",
    "def calculate_var_es(portfolio_name, weights, confidence_level=0.95, n_simulations=10000, method=\"GaussianCopula\"):\n",
    "    symbols_in_portfolio = list(weights.keys())\n",
    "\n",
    "    if method == \"GaussianCopula\":\n",
    "        # Step 1: Transform original returns to uniform using fitted distributions\n",
    "        uniform_data = {}\n",
    "        for symbol in symbols_in_portfolio:\n",
    "            returns = stock_returns[symbol]\n",
    "            best_model = best_models[symbol]\n",
    "            dist = fit_results[symbol][best_model]['dist']\n",
    "\n",
    "            # Calculate empirical CDFs\n",
    "            try:\n",
    "                u = np.array([dist.cdf(x) for x in returns])\n",
    "                # Handle boundary cases\n",
    "                u = np.minimum(np.maximum(u, 0.0001), 0.9999)\n",
    "                uniform_data[symbol] = u\n",
    "            except Exception as e:\n",
    "                print(f\"Error transforming {symbol} to uniform: {e}\")\n",
    "                # Fallback to empirical CDF\n",
    "                ecdf = ECDF(returns)\n",
    "                u = ecdf(returns)\n",
    "                uniform_data[symbol] = u\n",
    "\n",
    "        # Step 2: Transform uniform to standard normal\n",
    "        normal_data = {}\n",
    "        for symbol in symbols_in_portfolio:\n",
    "            try:\n",
    "                normal_data[symbol] = stats.norm.ppf(uniform_data[symbol])\n",
    "            except:\n",
    "                # Handle any numerical issues\n",
    "                u_clean = np.clip(uniform_data[symbol], 0.0001, 0.9999)\n",
    "                normal_data[symbol] = stats.norm.ppf(u_clean)\n",
    "\n",
    "        # Step 3: Estimate correlation matrix of transformed data\n",
    "        transformed_returns = pd.DataFrame({symbol: normal_data[symbol] for symbol in symbols_in_portfolio})\n",
    "        correlation_matrix = transformed_returns.corr().values\n",
    "\n",
    "        # Step 4: Generate correlated normal samples\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        simulated_normals = np.random.multivariate_normal(\n",
    "            mean=np.zeros(len(symbols_in_portfolio)),\n",
    "            cov=correlation_matrix,\n",
    "            size=n_simulations\n",
    "        )\n",
    "\n",
    "        # Step 5: Transform back to original distribution\n",
    "        simulated_returns = np.zeros((n_simulations, len(symbols_in_portfolio)))\n",
    "\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            z = simulated_normals[:, i]\n",
    "            u = stats.norm.cdf(z)\n",
    "\n",
    "            # Get correct distribution\n",
    "            best_model = best_models[symbol]\n",
    "            dist = fit_results[symbol][best_model]['dist']\n",
    "\n",
    "            # Transform uniform back to returns using inverse CDF (ppf)\n",
    "            try:\n",
    "                simulated_returns[:, i] = dist.ppf(u)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in inverse transform for {symbol}: {e}\")\n",
    "                # Fallback to empirical inverse CDF\n",
    "                x_sorted = np.sort(stock_returns[symbol])\n",
    "                indices = np.floor(u * len(x_sorted)).astype(int)\n",
    "                indices = np.minimum(indices, len(x_sorted)-1)\n",
    "                simulated_returns[:, i] = x_sorted[indices]\n",
    "\n",
    "        # Step 6: Calculate portfolio returns\n",
    "        portfolio_returns = np.zeros(n_simulations)\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            portfolio_returns += simulated_returns[:, i] * weights[symbol]\n",
    "\n",
    "    elif method == \"MultivariateNormal\":\n",
    "        # Simpler approach: assume multivariate normal directly\n",
    "        returns_data = np.column_stack([stock_returns[symbol] for symbol in symbols_in_portfolio])\n",
    "\n",
    "        # Estimate mean and covariance\n",
    "        mean_vector = np.zeros(len(symbols_in_portfolio))  # Assume 0% return as specified\n",
    "        cov_matrix = np.cov(returns_data, rowvar=False)\n",
    "\n",
    "        # Generate multivariate normal samples\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        simulated_returns = np.random.multivariate_normal(\n",
    "            mean=mean_vector,\n",
    "            cov=cov_matrix,\n",
    "            size=n_simulations\n",
    "        )\n",
    "\n",
    "        # Calculate portfolio returns\n",
    "        portfolio_returns = np.zeros(n_simulations)\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            portfolio_returns += simulated_returns[:, i] * weights[symbol]\n",
    "\n",
    "    # Calculate VaR and ES\n",
    "    sorted_returns = np.sort(portfolio_returns)\n",
    "    var_index = int(n_simulations * (1 - confidence_level))\n",
    "    var = -sorted_returns[var_index]\n",
    "    es = -np.mean(sorted_returns[:var_index])\n",
    "\n",
    "    return var, es\n",
    "\n",
    "# Extract portfolio weights from original structure\n",
    "# Note: We're using a different variable name to avoid conflict\n",
    "portfolio_weight_data = {}\n",
    "for portfolio in portfolios:\n",
    "    weights = {}\n",
    "    for symbol, info in portfolio_weights[portfolio].items():\n",
    "        weights[symbol] = info['weight']\n",
    "    portfolio_weight_data[portfolio] = weights\n",
    "\n",
    "# Calculate VaR and ES for each portfolio using both methods\n",
    "var_es_results = {}\n",
    "confidence_level = 0.95  # 95% confidence level\n",
    "\n",
    "for portfolio in portfolios:\n",
    "    weights = portfolio_weight_data[portfolio]\n",
    "\n",
    "    # Calculate using Gaussian Copula with fitted marginals\n",
    "    var_gc, es_gc = calculate_var_es(\n",
    "        portfolio, weights,\n",
    "        confidence_level=confidence_level,\n",
    "        method=\"GaussianCopula\"\n",
    "    )\n",
    "\n",
    "    # Calculate using Multivariate Normal\n",
    "    var_mvn, es_mvn = calculate_var_es(\n",
    "        portfolio, weights,\n",
    "        confidence_level=confidence_level,\n",
    "        method=\"MultivariateNormal\"\n",
    "    )\n",
    "\n",
    "    var_es_results[portfolio] = {\n",
    "        'GaussianCopula': {'VaR': var_gc, 'ES': es_gc},\n",
    "        'MultivariateNormal': {'VaR': var_mvn, 'ES': es_mvn}\n",
    "    }\n",
    "\n",
    "# Calculate for combined portfolio\n",
    "combined_weights = {}\n",
    "for portfolio in portfolios:\n",
    "    portfolio_value = portfolio_values[portfolio]\n",
    "    for symbol, info in portfolio_weights[portfolio].items():\n",
    "        weight = info['weight'] * portfolio_value / sum(portfolio_values.values())\n",
    "        if symbol in combined_weights:\n",
    "            combined_weights[symbol] += weight\n",
    "        else:\n",
    "            combined_weights[symbol] = weight\n",
    "\n",
    "# Calculate VaR and ES for combined portfolio\n",
    "var_gc, es_gc = calculate_var_es(\n",
    "    'Combined', combined_weights,\n",
    "    confidence_level=confidence_level,\n",
    "    method=\"GaussianCopula\"\n",
    ")\n",
    "\n",
    "var_mvn, es_mvn = calculate_var_es(\n",
    "    'Combined', combined_weights,\n",
    "    confidence_level=confidence_level,\n",
    "    method=\"MultivariateNormal\"\n",
    ")\n",
    "\n",
    "var_es_results['Combined'] = {\n",
    "    'GaussianCopula': {'VaR': var_gc, 'ES': es_gc},\n",
    "    'MultivariateNormal': {'VaR': var_mvn, 'ES': es_mvn}\n",
    "}\n",
    "\n",
    "# Report VaR and ES results\n",
    "print(\"\\n1-Day VaR and ES Results at 95% Confidence Level:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Portfolio':<10} {'VaR (GC)':<15} {'ES (GC)':<15} {'VaR (MVN)':<15} {'ES (MVN)':<15} {'VaR Diff %':<15} {'ES Diff %':<15}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for portfolio in var_es_results:\n",
    "    var_gc = var_es_results[portfolio]['GaussianCopula']['VaR']\n",
    "    es_gc = var_es_results[portfolio]['GaussianCopula']['ES']\n",
    "    var_mvn = var_es_results[portfolio]['MultivariateNormal']['VaR']\n",
    "    es_mvn = var_es_results[portfolio]['MultivariateNormal']['ES']\n",
    "\n",
    "    # Calculate percentage differences\n",
    "    var_diff_pct = (var_gc - var_mvn) / var_mvn * 100 if var_mvn != 0 else float('inf')\n",
    "    es_diff_pct = (es_gc - es_mvn) / es_mvn * 100 if es_mvn != 0 else float('inf')\n",
    "\n",
    "    print(f\"{portfolio:<10} {var_gc:<15.6f}  {es_gc:<15.6f}  {var_mvn:<15.6f} {es_mvn:<15.6f}  {var_diff_pct:<15.4f} {es_diff_pct:<15.4f}\")\n",
    "\n",
    "print(\"\\nNote: GC = Gaussian Copula with fitted marginals, MVN = Multivariate Normal\")\n",
    "print(\"      Positive difference percentages indicate that the Gaussian Copula method gives higher risk estimates\")\n",
    "\n",
    "# Additional analysis of the differences\n",
    "print(\"\\nComparison of Distribution Models vs. Normal Distribution:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"The differences between the two approaches can be attributed to:\")\n",
    "print(\"1. Skewness and fat tails captured by specialized distributions\")\n",
    "print(\"2. Non-linear dependency structures captured by the copula approach\")\n",
    "print(\"3. Different assumptions about the joint distribution of returns\")\n",
    "\n",
    "# Analyze which stocks deviate most from normality\n",
    "print(\"\\nStocks Deviating Most from Normality:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Symbol':<8} {'Best Model':<15} {'Skewness':<12} {'Excess Kurtosis':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for symbol in symbols:\n",
    "    returns = stock_returns[symbol]\n",
    "    skewness = stats.skew(returns)\n",
    "    kurtosis = stats.kurtosis(returns)  # Excess kurtosis (normal = 0)\n",
    "\n",
    "    print(f\"{symbol:<8} {best_models[symbol]:<15} {skewness:<12.4f} {kurtosis:<15.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "distribution_counts = Counter(best_models.values())\n",
    "\n",
    "print(\"\\n分布类型对应的股票数量统计：\")\n",
    "print(\"=\" * 40)\n",
    "for dist, count in distribution_counts.items():\n",
    "    print(f\"{dist:<15} : {count} stocks\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique portfolios: ['A', 'B', 'C']\n",
      "Portfolio weights successfully created.\n",
      "\n",
      "Fitting distributions to pre-holding period stock returns...\n",
      "\n",
      "Best Fit Distribution Models and Parameters:\n",
      "====================================================================================================\n",
      "Symbol   Best Model      Parameters\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SPY      Normal          (0.000985, 0.00823027)\n",
      "AAPL     GeneralizedT    (7.32705184, 0.00176004, 0.01070133)\n",
      "NVDA     GeneralizedT    (4.78942593, 0.0035959, 0.02167961)\n",
      "MSFT     GeneralizedT    (7.77186949, 0.0016953, 0.01361571)\n",
      "AMZN     GeneralizedT    (5.92185868, 0.00217428, 0.0168987)\n",
      "META     GeneralizedT    (4.21960376, 0.00276747, 0.01569186)\n",
      "GOOGL    GeneralizedT    (4.42004258, 0.0017383, 0.01418544)\n",
      "AVGO     GeneralizedT    (4.30167917, 0.00138822, 0.01470093)\n",
      "TSLA     GeneralizedT    (6.49117953, 0.00318664, 0.02780702)\n",
      "GOOG     GeneralizedT    (4.59360274, 0.00182357, 0.01447821)\n",
      "BRK-B    GeneralizedT    (6.74524696, 0.00067377, 0.00724056)\n",
      "JPM      GeneralizedT    (3.51880692, 0.00159525, 0.00884377)\n",
      "LLY      GeneralizedT    (3.23358817, 0.00165586, 0.01122477)\n",
      "V        GeneralizedT    (9.51965663, 0.00095938, 0.00873213)\n",
      "XOM      GeneralizedT    (7.88072967, -0.00021986, 0.01356079)\n",
      "UNH      GeneralizedT    (3.37101843, 0.00022572, 0.0086698)\n",
      "MA       GeneralizedT    (6.46819209, 0.00102464, 0.00888908)\n",
      "COST     GeneralizedT    (4.62116261, 0.0015835, 0.009026)\n",
      "PG       GeneralizedT    (5.51983912, 2.187e-05, 0.00757722)\n",
      "WMT      GeneralizedT    (6.04506726, 0.00096688, 0.00742733)\n",
      "HD       GeneralizedT    (4.53508785, 0.00070018, 0.01020933)\n",
      "NFLX     GeneralizedT    (3.64484136, 0.00091162, 0.01564827)\n",
      "JNJ      GeneralizedT    (3.60503826, -1.34e-06, 0.00700671)\n",
      "ABBV     GeneralizedT    (4.01955609, 0.00037586, 0.00865251)\n",
      "CRM      GeneralizedT    (5.10722255, 0.00200294, 0.01412393)\n",
      "BAC      GeneralizedT    (4.26752079, -0.00011622, 0.01272531)\n",
      "ORCL     GeneralizedT    (3.08185044, 0.0021289, 0.01082818)\n",
      "MRK      GeneralizedT    (8.06842812, 0.00023836, 0.01032434)\n",
      "CVX      GeneralizedT    (4.55344731, -8.92e-05, 0.01100463)\n",
      "KO       GeneralizedT    (5.21548072, 5.878e-05, 0.00657088)\n",
      "CSCO     GeneralizedT    (3.89493383, 0.00113959, 0.00847512)\n",
      "WFC      GeneralizedT    (5.00366906, 0.00098326, 0.01369201)\n",
      "ACN      GeneralizedT    (6.97220212, 0.00124094, 0.01151557)\n",
      "NOW      GeneralizedT    (3.95042611, 0.00389179, 0.01473725)\n",
      "MCD      GeneralizedT    (10.04277048, 0.00070566, 0.00788493)\n",
      "PEP      GeneralizedT    (5.80499472, 0.00013102, 0.00761036)\n",
      "IBM      GeneralizedT    (4.81519241, 0.00101536, 0.00758982)\n",
      "DIS      GeneralizedT    (4.9084054, 0.00022155, 0.01281408)\n",
      "TMO      GeneralizedT    (5.16094542, -9.467e-05, 0.01137947)\n",
      "LIN      GeneralizedT    (3.17283373, 0.00135203, 0.00829867)\n",
      "ABT      GeneralizedT    (6.22741603, -6.568e-05, 0.00995025)\n",
      "AMD      GeneralizedT    (4.69751877, 0.00261995, 0.02264792)\n",
      "ADBE     GeneralizedT    (5.878008, 0.00256884, 0.01635708)\n",
      "PM       GeneralizedT    (8.1562215, 7.079e-05, 0.00900558)\n",
      "ISRG     GeneralizedT    (4.70021557, 0.00154407, 0.0137455)\n",
      "GE       SkewNormal      (1.82249234, -0.01199416, 0.02123692)\n",
      "GS       GeneralizedT    (5.50564289, 0.00086959, 0.01220379)\n",
      "INTU     GeneralizedT    (5.57011791, 0.00203526, 0.01485176)\n",
      "CAT      GeneralizedT    (4.45013631, 0.00091466, 0.01320514)\n",
      "QCOM     GeneralizedT    (5.220655, 0.00135796, 0.01561377)\n",
      "TXN      GeneralizedT    (9.15095462, 0.00021763, 0.01336299)\n",
      "VZ       GeneralizedT    (3.27124148, 0.00034792, 0.00910633)\n",
      "AXP      GeneralizedT    (4.7185681, 0.00123521, 0.0123052)\n",
      "T        GeneralizedT    (3.02149762, 6.288e-05, 0.01003867)\n",
      "BKNG     GeneralizedT    (8.12043383, 0.00208597, 0.0135332)\n",
      "SPGI     GeneralizedT    (4.16496256, 0.00173211, 0.00992714)\n",
      "MS       GeneralizedT    (4.49436035, 0.00038078, 0.0122768)\n",
      "RTX      GeneralizedT    (3.20868595, -0.00035334, 0.00909624)\n",
      "PLTR     GeneralizedT    (3.11032753, 0.00134457, 0.02781572)\n",
      "PFE      GeneralizedT    (4.09258281, -0.00192749, 0.01057259)\n",
      "BLK      GeneralizedT    (7.93368605, 0.00051947, 0.012039)\n",
      "DHR      GeneralizedT    (5.30548175, 0.00045194, 0.01192899)\n",
      "NEE      GeneralizedT    (2.95117787, -0.00076447, 0.01067441)\n",
      "HON      GeneralizedT    (5.72908595, 0.00037982, 0.00930099)\n",
      "CMCSA    GeneralizedT    (4.55605759, 0.00090869, 0.01062443)\n",
      "PGR      GeneralizedT    (2.64676743, 0.00124674, 0.00993869)\n",
      "LOW      NIG             (63.63379063, 7.97831389, -0.00113827, 0.01408374)\n",
      "AMGN     GeneralizedT    (5.94448029, 3.499e-05, 0.01074017)\n",
      "UNP      GeneralizedT    (3.98526301, 0.0003117, 0.0099356)\n",
      "TJX      GeneralizedT    (10.19180221, 0.00080818, 0.00902108)\n",
      "AMAT     SkewNormal      (1.40541978, -0.01582076, 0.02799633)\n",
      "UBER     GeneralizedT    (9.44055342, 0.00354852, 0.0200986)\n",
      "C        GeneralizedT    (4.16803442, 0.00073837, 0.01184787)\n",
      "BSX      GeneralizedT    (3.54086, 0.00104552, 0.00865211)\n",
      "ETN      GeneralizedT    (3.8783439, 0.00236338, 0.01202696)\n",
      "COP      GeneralizedT    (5.8301282, 0.00019623, 0.01449162)\n",
      "BA       GeneralizedT    (4.70300787, 0.0013277, 0.01309473)\n",
      "BX       GeneralizedT    (6.3059333, 0.00277636, 0.01820997)\n",
      "SYK      GeneralizedT    (2.66310918, 0.00096561, 0.008678)\n",
      "PANW     GeneralizedT    (3.32214521, 0.0032621, 0.01555676)\n",
      "ADP      GeneralizedT    (3.39026684, 0.00057481, 0.00851731)\n",
      "FI       GeneralizedT    (3.72162785, 0.00093909, 0.00885607)\n",
      "ANET     GeneralizedT    (2.74406401, 0.00238797, 0.01557043)\n",
      "GILD     GeneralizedT    (8.56930944, 4.86e-05, 0.01120598)\n",
      "BMY      GeneralizedT    (4.35979899, -0.00095604, 0.00906315)\n",
      "SCHW     GeneralizedT    (2.83913538, -0.0001954, 0.01585662)\n",
      "TMUS     GeneralizedT    (5.56930757, 0.00113596, 0.00953262)\n",
      "DE       GeneralizedT    (5.6007237, 0.00034151, 0.01369609)\n",
      "ADI      GeneralizedT    (6.36393808, 0.0009286, 0.0135401)\n",
      "VRTX     GeneralizedT    (4.00697129, 0.00137905, 0.01041982)\n",
      "SBUX     GeneralizedT    (4.18938608, -8.21e-06, 0.00961351)\n",
      "MMC      GeneralizedT    (5.36067464, 0.00112148, 0.00833078)\n",
      "MDT      GeneralizedT    (4.58297189, 0.00045716, 0.01037367)\n",
      "CB       GeneralizedT    (5.69179653, 0.0003543, 0.01032532)\n",
      "LMT      GeneralizedT    (3.70332478, -0.00016025, 0.00739249)\n",
      "KKR      GeneralizedT    (7.22819361, 0.00254548, 0.01701882)\n",
      "MU       SkewNormal      (2.21502803, -0.02111968, 0.03275535)\n",
      "PLD      GeneralizedT    (6.67570246, 0.00088595, 0.01394534)\n",
      "LRCX     GeneralizedT    (4.95510526, 0.00173803, 0.01803918)\n",
      "EQIX     GeneralizedT    (5.29593928, 0.00116643, 0.01221178)\n",
      "\n",
      "Calculating VaR and ES using Gaussian Copula with fitted marginals...\n",
      "\n",
      "1-Day VaR and ES Results at 95% Confidence Level:\n",
      "====================================================================================================\n",
      "Portfolio  VaR (GC)        ES (GC)         VaR (MVN)       ES (MVN)        VaR Diff %      ES Diff %      \n",
      "----------------------------------------------------------------------------------------------------\n",
      "A          0.013671         0.018482         0.014365        0.017848         -4.8273         3.5532         \n",
      "B          0.012399         0.017007         0.012228        0.015582         1.3968          9.1438         \n",
      "C          0.015236         0.021319         0.016230        0.020089         -6.1206         6.1207         \n",
      "Combined   0.012808         0.017353         0.013180        0.016571         -2.8250         4.7249         \n",
      "\n",
      "Note: GC = Gaussian Copula with fitted marginals, MVN = Multivariate Normal\n",
      "      Positive difference percentages indicate that the Gaussian Copula method gives higher risk estimates\n",
      "\n",
      "Comparison of Distribution Models vs. Normal Distribution:\n",
      "====================================================================================================\n",
      "The differences between the two approaches can be attributed to:\n",
      "1. Skewness and fat tails captured by specialized distributions\n",
      "2. Non-linear dependency structures captured by the copula approach\n",
      "3. Different assumptions about the joint distribution of returns\n",
      "\n",
      "Stocks Deviating Most from Normality:\n",
      "================================================================================\n",
      "Symbol   Best Model      Skewness     Excess Kurtosis\n",
      "--------------------------------------------------------------------------------\n",
      "SPY      Normal          -0.0264      -0.1808        \n",
      "AAPL     GeneralizedT    0.0117       1.3803         \n",
      "NVDA     GeneralizedT    2.3050       15.0097        \n",
      "MSFT     GeneralizedT    0.3725       1.3965         \n",
      "AMZN     GeneralizedT    0.1589       2.0492         \n",
      "META     GeneralizedT    3.6439       29.1858        \n",
      "GOOGL    GeneralizedT    -0.2737      3.8062         \n",
      "AVGO     GeneralizedT    1.3168       4.9104         \n",
      "TSLA     GeneralizedT    0.1769       0.9274         \n",
      "GOOG     GeneralizedT    -0.2850      3.6452         \n",
      "BRK-B    GeneralizedT    -0.0157      1.3080         \n",
      "JPM      GeneralizedT    0.0834       5.4599         \n",
      "LLY      GeneralizedT    2.1702       16.5953        \n",
      "V        GeneralizedT    0.0975       0.6306         \n",
      "XOM      GeneralizedT    0.1861       0.9510         \n",
      "UNH      GeneralizedT    0.0920       6.1215         \n",
      "MA       GeneralizedT    -0.3158      3.3989         \n",
      "COST     GeneralizedT    0.9064       4.9568         \n",
      "PG       GeneralizedT    -0.0215      1.4783         \n",
      "WMT      GeneralizedT    -2.3516      17.5468        \n",
      "HD       GeneralizedT    -0.3118      3.4988         \n",
      "NFLX     GeneralizedT    1.5501       9.1926         \n",
      "JNJ      GeneralizedT    0.4918       6.4247         \n",
      "ABBV     GeneralizedT    -1.0113      7.5701         \n",
      "CRM      GeneralizedT    1.3005       6.4508         \n",
      "BAC      GeneralizedT    0.1650       1.7700         \n",
      "ORCL     GeneralizedT    -2.4978      17.4316        \n",
      "MRK      GeneralizedT    -0.0799      0.8217         \n",
      "CVX      GeneralizedT    -0.3635      2.3977         \n",
      "KO       GeneralizedT    -0.6793      4.3859         \n",
      "CSCO     GeneralizedT    -1.8648      14.5277        \n",
      "WFC      GeneralizedT    -0.2059      1.8514         \n",
      "ACN      GeneralizedT    0.3451       2.6573         \n",
      "NOW      GeneralizedT    -0.4871      1.2491         \n",
      "MCD      GeneralizedT    -0.1877      0.5268         \n",
      "PEP      GeneralizedT    -0.6763      3.3992         \n",
      "IBM      GeneralizedT    -0.0866      3.5663         \n",
      "DIS      GeneralizedT    -0.2118      3.5473         \n",
      "TMO      GeneralizedT    -0.0985      1.3913         \n",
      "LIN      GeneralizedT    0.0491       2.3628         \n",
      "ABT      GeneralizedT    0.8565       6.3120         \n",
      "AMD      GeneralizedT    0.5511       2.2083         \n",
      "ADBE     GeneralizedT    -0.1861      1.6118         \n",
      "PM       GeneralizedT    -0.2965      1.3960         \n",
      "ISRG     GeneralizedT    0.4285       4.8215         \n",
      "GE       SkewNormal      0.7029       1.7958         \n",
      "GS       GeneralizedT    -0.1956      1.8179         \n",
      "INTU     GeneralizedT    -0.3833      1.7115         \n",
      "CAT      GeneralizedT    0.4816       4.5133         \n",
      "QCOM     GeneralizedT    -0.1064      2.0764         \n",
      "TXN      GeneralizedT    0.1275       0.8316         \n",
      "VZ       GeneralizedT    0.6876       9.4597         \n",
      "AXP      GeneralizedT    0.7233       6.2722         \n",
      "T        GeneralizedT    -0.3011      9.3424         \n",
      "BKNG     GeneralizedT    0.5095       2.0890         \n",
      "SPGI     GeneralizedT    -0.3702      5.7721         \n",
      "MS       GeneralizedT    0.2411       2.7802         \n",
      "RTX      GeneralizedT    -1.1740      12.1749        \n",
      "PLTR     GeneralizedT    1.4339       5.8755         \n",
      "PFE      GeneralizedT    -0.2605      2.8555         \n",
      "BLK      GeneralizedT    0.4244       1.2857         \n",
      "DHR      GeneralizedT    -0.6424      4.3022         \n",
      "NEE      GeneralizedT    -0.9016      6.6754         \n",
      "HON      GeneralizedT    -0.4274      2.5569         \n",
      "CMCSA    GeneralizedT    0.6269       11.3392        \n",
      "PGR      GeneralizedT    -0.8212      12.9100        \n",
      "LOW      NIG             -0.0073      1.6908         \n",
      "AMGN     GeneralizedT    0.5071       1.3552         \n",
      "UNP      GeneralizedT    2.3172       14.8830        \n",
      "TJX      GeneralizedT    0.0345       0.9860         \n",
      "AMAT     SkewNormal      0.3140       0.4762         \n",
      "UBER     GeneralizedT    0.3931       1.7761         \n",
      "C        GeneralizedT    -0.1994      2.7246         \n",
      "BSX      GeneralizedT    0.0372       3.8163         \n",
      "ETN      GeneralizedT    -0.2612      2.6167         \n",
      "COP      GeneralizedT    0.4408       2.9151         \n",
      "BA       GeneralizedT    0.2340       2.7889         \n",
      "BX       GeneralizedT    -0.1473      1.1238         \n",
      "SYK      GeneralizedT    0.8998       8.3554         \n",
      "PANW     GeneralizedT    1.0348       7.6397         \n",
      "ADP      GeneralizedT    -1.3022      10.1821        \n",
      "FI       GeneralizedT    0.8162       9.0804         \n",
      "ANET     GeneralizedT    1.0243       13.5262        \n",
      "GILD     GeneralizedT    -0.0218      0.6773         \n",
      "BMY      GeneralizedT    -0.7258      3.3513         \n",
      "SCHW     GeneralizedT    -0.4116      6.2538         \n",
      "TMUS     GeneralizedT    -0.5563      2.1798         \n",
      "DE       GeneralizedT    -0.1116      2.3091         \n",
      "ADI      GeneralizedT    -0.0490      2.8135         \n",
      "VRTX     GeneralizedT    2.0018       18.6757        \n",
      "SBUX     GeneralizedT    0.0732       13.4239        \n",
      "MMC      GeneralizedT    -0.6687      3.0487         \n",
      "MDT      GeneralizedT    -0.0036      1.5698         \n",
      "CB       GeneralizedT    -0.2190      2.5729         \n",
      "LMT      GeneralizedT    1.5414       15.4888        \n",
      "KKR      GeneralizedT    -0.0047      1.2228         \n",
      "MU       SkewNormal      0.7983       1.3645         \n",
      "PLD      GeneralizedT    0.2825       1.5580         \n",
      "LRCX     GeneralizedT    0.6398       1.3498         \n",
      "EQIX     GeneralizedT    -0.0953      1.3638         \n",
      "\n",
      "分布类型对应的股票数量统计：\n",
      "========================================\n",
      "Normal          : 1 stocks\n",
      "GeneralizedT    : 95 stocks\n",
      "SkewNormal      : 3 stocks\n",
      "NIG             : 1 stocks\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T02:08:19.065007Z",
     "start_time": "2025-04-19T02:07:15.654559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Improved Risk Parity Portfolio Optimization using ES\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "# Define a much more efficient function to calculate marginal risk contributions\n",
    "def calculate_marginal_risk_contributions(weights, portfolio_name, confidence_level=0.95, n_simulations=500):\n",
    "    \"\"\"\n",
    "    Calculate marginal risk contributions to ES for each asset in the portfolio more efficiently.\n",
    "\n",
    "    Args:\n",
    "        weights: Dictionary with asset weights\n",
    "        portfolio_name: Name of the portfolio\n",
    "        confidence_level: Confidence level for ES calculation\n",
    "        n_simulations: Number of simulations for Monte Carlo\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of marginal risk contributions indexed by symbol\n",
    "    \"\"\"\n",
    "    symbols_in_portfolio = list(weights.keys())\n",
    "\n",
    "    # Convert dictionary to numpy array for faster computation\n",
    "    weights_array = np.array([weights[symbol] for symbol in symbols_in_portfolio])\n",
    "\n",
    "    # Create returns matrix for faster computation\n",
    "    returns_matrix = np.zeros((len(stock_returns[symbols_in_portfolio[0]]), len(symbols_in_portfolio)))\n",
    "    for i, symbol in enumerate(symbols_in_portfolio):\n",
    "        returns_matrix[:, i] = stock_returns[symbol]\n",
    "\n",
    "    # Calculate covariance matrix for approximating initial marginal contributions\n",
    "    cov_matrix = np.cov(returns_matrix, rowvar=False)\n",
    "\n",
    "    # Approximate marginal contributions using covariance matrix\n",
    "    # This gives a reasonable starting point while being much faster\n",
    "    portfolio_variance = weights_array.T @ cov_matrix @ weights_array\n",
    "    marginal_contrib_approx = (cov_matrix @ weights_array) / np.sqrt(portfolio_variance)\n",
    "\n",
    "    # For small simulations, use the covariance approximation\n",
    "    if n_simulations < 300:\n",
    "        # Create result dictionary\n",
    "        mrc = {}\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            mrc[symbol] = marginal_contrib_approx[i]\n",
    "        return mrc\n",
    "\n",
    "    # For portfolios, use a more accurate but still efficient simulation approach\n",
    "    try:\n",
    "        # Use Gaussian Copula method with minimal simulations\n",
    "        np.random.seed(42)\n",
    "\n",
    "        # Transform original returns to standard normal\n",
    "        transformed_returns = np.zeros_like(returns_matrix)\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            # Use empirical CDF for speed\n",
    "            ecdf = ECDF(returns_matrix[:, i])\n",
    "            u = ecdf(returns_matrix[:, i])\n",
    "            u = np.clip(u, 0.001, 0.999)  # Avoid boundary issues\n",
    "            transformed_returns[:, i] = stats.norm.ppf(u)\n",
    "\n",
    "        # Calculate correlation matrix (faster than full copula transformation)\n",
    "        corr_matrix = np.corrcoef(transformed_returns, rowvar=False)\n",
    "\n",
    "        # Generate correlated normal samples\n",
    "        simulated_normals = np.random.multivariate_normal(\n",
    "            mean=np.zeros(len(symbols_in_portfolio)),\n",
    "            cov=corr_matrix,\n",
    "            size=n_simulations\n",
    "        )\n",
    "\n",
    "        # Transform back to return space using simple method\n",
    "        simulated_returns = np.zeros((n_simulations, len(symbols_in_portfolio)))\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            # Use percentile mapping for speed\n",
    "            u = stats.norm.cdf(simulated_normals[:, i])\n",
    "            perc_indices = np.floor(u * len(returns_matrix)).astype(int)\n",
    "            perc_indices = np.clip(perc_indices, 0, len(returns_matrix) - 1)\n",
    "            sorted_returns = np.sort(returns_matrix[:, i])\n",
    "            simulated_returns[:, i] = sorted_returns[perc_indices]\n",
    "\n",
    "        # Calculate portfolio returns\n",
    "        portfolio_returns = simulated_returns @ weights_array\n",
    "\n",
    "        # Calculate ES\n",
    "        sorted_indices = np.argsort(portfolio_returns)\n",
    "        var_index = int(n_simulations * (1 - confidence_level))\n",
    "        tail_indices = sorted_indices[:var_index]\n",
    "\n",
    "        # Calculate marginal contributions as average contribution in the tail\n",
    "        mrc = {}\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            # Average contribution of this asset to losses in the tail\n",
    "            tail_contribution = np.mean(simulated_returns[tail_indices, i])\n",
    "            mrc[symbol] = -tail_contribution / (-np.mean(portfolio_returns[tail_indices]))\n",
    "\n",
    "        return mrc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in ES calculation for {portfolio_name}: {e}\")\n",
    "        # Fallback to approximation if simulation fails\n",
    "        mrc = {}\n",
    "        for i, symbol in enumerate(symbols_in_portfolio):\n",
    "            mrc[symbol] = marginal_contrib_approx[i]\n",
    "        return mrc\n",
    "\n",
    "# Define objective function for risk parity optimization\n",
    "def risk_parity_objective(raw_weights, portfolio_name, symbols, confidence_level=0.95, n_simulations=500):\n",
    "    \"\"\"\n",
    "    Objective function for risk parity optimization with efficiency improvements.\n",
    "    We want to minimize the sum of squared differences between risk contributions.\n",
    "\n",
    "    Args:\n",
    "        raw_weights: Optimization variable (raw weights before normalization)\n",
    "        portfolio_name: Name of the portfolio\n",
    "        symbols: List of symbols in the portfolio\n",
    "        confidence_level: Confidence level for ES\n",
    "        n_simulations: Number of simulations\n",
    "\n",
    "    Returns:\n",
    "        Sum of squared differences between risk contributions\n",
    "    \"\"\"\n",
    "    # Ensure positive weights and normalize to sum to 1\n",
    "    weights = np.maximum(raw_weights, 1e-8)\n",
    "    weights = weights / np.sum(weights)\n",
    "\n",
    "    # Convert to dictionary format\n",
    "    weights_dict = {symbols[i]: weights[i] for i in range(len(symbols))}\n",
    "\n",
    "    # For portfolio with low simulation count, use variance-based approximation\n",
    "    if n_simulations < 300:\n",
    "        # Get returns data for all symbols\n",
    "        returns_matrix = np.zeros((len(stock_returns[symbols[0]]), len(symbols)))\n",
    "        for i, symbol in enumerate(symbols):\n",
    "            returns_matrix[:, i] = stock_returns[symbol]\n",
    "\n",
    "        # Calculate covariance matrix\n",
    "        cov_matrix = np.cov(returns_matrix, rowvar=False)\n",
    "\n",
    "        # Calculate portfolio variance\n",
    "        portfolio_variance = weights @ cov_matrix @ weights\n",
    "\n",
    "        # Calculate marginal risk contributions\n",
    "        marginal_contributions = cov_matrix @ weights / np.sqrt(portfolio_variance)\n",
    "\n",
    "        # Calculate risk contributions\n",
    "        risk_contributions = weights * marginal_contributions\n",
    "\n",
    "        # Calculate target risk contribution\n",
    "        target_risk = np.sum(risk_contributions) / len(symbols)\n",
    "\n",
    "        # Return sum of squared deviations\n",
    "        return np.sum((risk_contributions - target_risk) ** 2)\n",
    "\n",
    "    # For other portfolios, use ES-based risk contributions\n",
    "    else:\n",
    "        # Calculate marginal risk contributions\n",
    "        mrc = calculate_marginal_risk_contributions(\n",
    "            weights_dict,\n",
    "            portfolio_name,\n",
    "            confidence_level,\n",
    "            n_simulations\n",
    "        )\n",
    "\n",
    "        # Calculate risk contributions\n",
    "        rc = {symbol: weights_dict[symbol] * mrc[symbol] for symbol in symbols}\n",
    "        total_rc = sum(rc.values())\n",
    "\n",
    "        # Target: equal risk contribution from each asset\n",
    "        target_rc = total_rc / len(symbols)\n",
    "\n",
    "        # Sum of squared deviations from target\n",
    "        return sum((rc[symbol] - target_rc) ** 2 for symbol in symbols)\n",
    "\n",
    "# Function to create risk parity portfolio with multiple starts\n",
    "def optimize_with_multiple_starts(portfolio_name, symbols, n_attempts=5, confidence_level=0.95, n_simulations=500):\n",
    "    \"\"\"\n",
    "    Optimize risk parity portfolio with multiple random starts to avoid local minima.\n",
    "\n",
    "    Args:\n",
    "        portfolio_name: Name of the portfolio\n",
    "        symbols: List of symbols in the portfolio\n",
    "        n_attempts: Number of optimization attempts with different initial weights\n",
    "        confidence_level: Confidence level for ES calculation\n",
    "        n_simulations: Number of simulations for Monte Carlo\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of optimized weights\n",
    "    \"\"\"\n",
    "    print(f\"Optimizing portfolio {portfolio_name} with {n_attempts} different starting points...\")\n",
    "    best_result = None\n",
    "    best_objective = float('inf')\n",
    "    n_assets = len(symbols)\n",
    "\n",
    "    for i in range(n_attempts):\n",
    "        # Generate different initial weights for each attempt\n",
    "        np.random.seed(42 + i)\n",
    "\n",
    "        # Use different strategies for different attempts\n",
    "        if i == 0:\n",
    "            # First attempt: equal weights\n",
    "            initial_weights = np.ones(n_assets) / n_assets\n",
    "        elif i == 1:\n",
    "            # Second attempt: inverse variance weights (good for risk parity)\n",
    "            # Get returns data\n",
    "            returns_matrix = np.zeros((len(stock_returns[symbols[0]]), len(symbols)))\n",
    "            for j, symbol in enumerate(symbols):\n",
    "                returns_matrix[:, j] = stock_returns[symbol]\n",
    "\n",
    "            # Calculate variances and inverse variance weights\n",
    "            variances = np.var(returns_matrix, axis=0)\n",
    "            inv_var = 1.0 / (variances + 1e-8)  # Add small constant to avoid division by zero\n",
    "            initial_weights = inv_var / np.sum(inv_var)\n",
    "        elif i == 2:\n",
    "            # Third attempt: random weights with uniform concentration\n",
    "            alpha = np.ones(n_assets)  # Equal concentration\n",
    "            initial_weights = np.random.dirichlet(alpha)\n",
    "        elif i == 3:\n",
    "            # Fourth attempt: high concentration on low volatility assets\n",
    "            returns_matrix = np.zeros((len(stock_returns[symbols[0]]), len(symbols)))\n",
    "            for j, symbol in enumerate(symbols):\n",
    "                returns_matrix[:, j] = stock_returns[symbol]\n",
    "\n",
    "            volatilities = np.std(returns_matrix, axis=0)\n",
    "            alpha = 1.0 / (volatilities + 1e-8)\n",
    "            alpha = alpha / np.mean(alpha) * 5  # Scale to reasonable concentration\n",
    "            initial_weights = np.random.dirichlet(alpha)\n",
    "        else:\n",
    "            # Fifth attempt: high concentration on high volatility assets (opposite of fourth)\n",
    "            returns_matrix = np.zeros((len(stock_returns[symbols[0]]), len(symbols)))\n",
    "            for j, symbol in enumerate(symbols):\n",
    "                returns_matrix[:, j] = stock_returns[symbol]\n",
    "\n",
    "            volatilities = np.std(returns_matrix, axis=0)\n",
    "            alpha = volatilities + 1e-8\n",
    "            alpha = alpha / np.mean(alpha) * 5  # Scale to reasonable concentration\n",
    "            initial_weights = np.random.dirichlet(alpha)\n",
    "\n",
    "        # Define constraints\n",
    "        constraints = (\n",
    "            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Sum of weights = 1\n",
    "        )\n",
    "\n",
    "        # Define bounds\n",
    "        bounds = [(0.001, 1) for _ in range(n_assets)]  # Lower bound to avoid zero weights\n",
    "\n",
    "        # Set optimizer options - use consistent settings for all portfolios\n",
    "        optimizer_options = {\n",
    "            'maxiter': 50,\n",
    "            'ftol': 1e-4,\n",
    "            'eps': 1e-3,\n",
    "            'disp': True\n",
    "        }\n",
    "\n",
    "        if i > 0:\n",
    "            # For all portfolios, use more aggressive settings on later attempts\n",
    "            optimizer_options = {\n",
    "                'maxiter': 100,  # Increased iterations\n",
    "                'ftol': 1e-5,    # Tighter tolerance\n",
    "                'eps': 5e-4,     # Smaller step size\n",
    "                'disp': True\n",
    "            }\n",
    "\n",
    "        # Start timer\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Optimize with SLSQP\n",
    "        print(f\"Attempt {i+1}/{n_attempts} for portfolio {portfolio_name}...\")\n",
    "        result = minimize(\n",
    "            risk_parity_objective,\n",
    "            initial_weights,\n",
    "            args=(portfolio_name, symbols, confidence_level, n_simulations),\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            options=optimizer_options\n",
    "        )\n",
    "\n",
    "        # Get optimized weights and normalize to ensure sum=1\n",
    "        optimized_weights = result.x\n",
    "        optimized_weights = optimized_weights / np.sum(optimized_weights)\n",
    "\n",
    "        # Calculate objective function value\n",
    "        objective = risk_parity_objective(\n",
    "            optimized_weights,\n",
    "            portfolio_name,\n",
    "            symbols,\n",
    "            confidence_level,\n",
    "            n_simulations\n",
    "        )\n",
    "\n",
    "        print(f\"Attempt {i+1} completed in {time.time() - start_time:.2f} seconds with objective value: {objective:.6f}\")\n",
    "\n",
    "        # Update if this is better than previous best\n",
    "        if objective < best_objective:\n",
    "            best_objective = objective\n",
    "            best_result = {symbols[i]: optimized_weights[i] for i in range(n_assets)}\n",
    "            print(f\"New best result found in attempt {i+1} with objective value: {objective:.6f}\")\n",
    "\n",
    "    print(f\"Best optimization result for portfolio {portfolio_name} with objective value: {best_objective:.6f}\")\n",
    "    return best_result\n",
    "\n",
    "# Function to create risk parity portfolio (original)\n",
    "def create_risk_parity_portfolio(portfolio_name, symbols, initial_weights=None, confidence_level=0.95, n_simulations=500, optimizer_options=None):\n",
    "    \"\"\"\n",
    "    Create a risk parity portfolio for the given symbols with improved efficiency.\n",
    "\n",
    "    Args:\n",
    "        portfolio_name: Name of the portfolio\n",
    "        symbols: List of symbols in the portfolio\n",
    "        initial_weights: Initial weights to start optimization (equal if None)\n",
    "        confidence_level: Confidence level for ES\n",
    "        n_simulations: Number of simulations for Monte Carlo\n",
    "        optimizer_options: Dictionary of options for the optimizer\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of optimized weights\n",
    "    \"\"\"\n",
    "    n_assets = len(symbols)\n",
    "\n",
    "    # Start with equal weights if not provided\n",
    "    if initial_weights is None:\n",
    "        initial_weights = np.ones(n_assets) / n_assets\n",
    "\n",
    "    # Add random perturbation if desired\n",
    "    np.random.seed(42)\n",
    "    perturbation = np.random.uniform(0.9, 1.1, size=n_assets)\n",
    "    initial_weights = initial_weights * perturbation\n",
    "    initial_weights = initial_weights / np.sum(initial_weights)\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = (\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Sum of weights = 1\n",
    "    )\n",
    "\n",
    "    # Define bounds\n",
    "    bounds = [(0.001, 1) for _ in range(n_assets)]  # Lower bound to avoid zero weights\n",
    "\n",
    "    # Set default optimizer options if none provided\n",
    "    if optimizer_options is None:\n",
    "        optimizer_options = {\n",
    "            'maxiter': 150,\n",
    "            'ftol': 1e-4,\n",
    "            'eps': 1e-3,\n",
    "            'disp': True\n",
    "        }\n",
    "\n",
    "    # Optimize with SLSQP\n",
    "    print(f\"Optimizing risk parity portfolio for {portfolio_name}...\")\n",
    "    result = minimize(\n",
    "        risk_parity_objective,\n",
    "        initial_weights,\n",
    "        args=(portfolio_name, symbols, confidence_level, n_simulations),\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints,\n",
    "        options=optimizer_options\n",
    "    )\n",
    "\n",
    "    # Get optimized weights and normalize again to ensure sum=1\n",
    "    optimized_weights = result.x\n",
    "    optimized_weights = optimized_weights / np.sum(optimized_weights)\n",
    "\n",
    "    # Convert to dictionary\n",
    "    return {symbols[i]: optimized_weights[i] for i in range(n_assets)}\n",
    "\n",
    "# Step 5: Create risk parity portfolios for each sub-portfolio\n",
    "print(\"\\n=== Creating Risk Parity Portfolios ===\")\n",
    "# Use portfolios from initial_portfolio\n",
    "portfolios = initial_portfolio['Portfolio'].unique().tolist()\n",
    "risk_parity_weights = {}\n",
    "\n",
    "# Define parameters for each portfolio - give them all 500 simulations now\n",
    "portfolio_params = {\n",
    "    'A': {'n_sim': 5000, 'ftol': 1e-4, 'maxiter': 50, 'eps': 1e-3, 'multi_start': True},\n",
    "    'B': {'n_sim': 5000, 'ftol': 1e-4, 'maxiter': 50, 'eps': 1e-3, 'multi_start': True},\n",
    "    'C': {'n_sim': 5000, 'ftol': 1e-5, 'maxiter': 100, 'eps': 5e-4, 'multi_start': True}\n",
    "}\n",
    "\n",
    "# Process each portfolio\n",
    "for portfolio in portfolios:\n",
    "    # Get parameters for this portfolio\n",
    "    params = portfolio_params.get(portfolio, {'n_sim': 500, 'ftol': 1e-4, 'maxiter': 50, 'eps': 1e-3, 'multi_start': False})\n",
    "\n",
    "    # Get symbols for this portfolio\n",
    "    portfolio_df = initial_portfolio[initial_portfolio['Portfolio'] == portfolio]\n",
    "    portfolio_symbols = portfolio_df['Symbol'].unique().tolist()\n",
    "\n",
    "    # Get initial weights\n",
    "    portfolio_weights_dict = {}\n",
    "    for symbol in portfolio_symbols:\n",
    "        weight = portfolio_weights[portfolio][symbol]['weight']\n",
    "        portfolio_weights_dict[symbol] = weight\n",
    "\n",
    "    # Convert to numpy array\n",
    "    initial_weights = np.array([portfolio_weights_dict[symbol] for symbol in portfolio_symbols])\n",
    "\n",
    "    # For portfolio C, use multi-start optimization\n",
    "    if params['multi_start']:\n",
    "        print(f\"Using multi-start optimization for portfolio {portfolio} with {params['n_sim']} simulations\")\n",
    "        risk_parity_weights[portfolio] = optimize_with_multiple_starts(\n",
    "            portfolio,\n",
    "            portfolio_symbols,\n",
    "            n_attempts=3,  # Try 3 different starting points\n",
    "            confidence_level=0.95,\n",
    "            n_simulations=params['n_sim']\n",
    "        )\n",
    "    else:\n",
    "        # Define optimizer options\n",
    "        optimizer_options = {\n",
    "            'maxiter': params['maxiter'],\n",
    "            'ftol': params['ftol'],\n",
    "            'eps': params['eps'],\n",
    "            'disp': True\n",
    "        }\n",
    "\n",
    "        # Create risk parity portfolio\n",
    "        risk_parity_weights[portfolio] = create_risk_parity_portfolio(\n",
    "            portfolio,\n",
    "            portfolio_symbols,\n",
    "            initial_weights=initial_weights,\n",
    "            confidence_level=0.95,\n",
    "            n_simulations=params['n_sim'],\n",
    "            optimizer_options=optimizer_options\n",
    "        )\n",
    "\n",
    "# Step 6: Calculate VaR and ES for risk parity portfolios\n",
    "print(\"\\n=== Risk Metrics for Risk Parity Portfolios ===\")\n",
    "risk_parity_var_es = {}\n",
    "\n",
    "for portfolio in portfolios:\n",
    "    # Calculate VaR and ES for risk parity portfolio\n",
    "    var_gc, es_gc = calculate_var_es(\n",
    "        portfolio,\n",
    "        risk_parity_weights[portfolio],\n",
    "        confidence_level=0.95,\n",
    "        method=\"GaussianCopula\",\n",
    "        n_simulations=1000\n",
    "    )\n",
    "\n",
    "    risk_parity_var_es[portfolio] = {\n",
    "        'VaR': var_gc,\n",
    "        'ES': es_gc\n",
    "    }\n",
    "\n",
    "# Step 7: Compare original vs risk parity portfolios\n",
    "print(\"\\nComparison of Original vs Risk Parity Portfolios:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Portfolio':<10} {'Original VaR':<15} {'Original ES':<15} {'RP VaR':<15} {'RP ES':<15} {'VaR Change %':<15} {'ES Change %':<15}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for portfolio in portfolios:\n",
    "    # Check if we have risk metrics for the original portfolio\n",
    "    if portfolio not in var_es_results:\n",
    "        print(f\"Calculating original risk metrics for portfolio {portfolio}...\")\n",
    "        # Calculate VaR and ES for the original portfolio\n",
    "        weights = {}\n",
    "        for symbol in portfolio_weights[portfolio]:\n",
    "            weights[symbol] = portfolio_weights[portfolio][symbol]['weight']\n",
    "\n",
    "        var_gc, es_gc = calculate_var_es(\n",
    "            portfolio, weights,\n",
    "            confidence_level=0.95,\n",
    "            method=\"GaussianCopula\",\n",
    "            n_simulations=10000\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        var_es_results[portfolio] = {\n",
    "            'GaussianCopula': {'VaR': var_gc, 'ES': es_gc}\n",
    "        }\n",
    "\n",
    "    # Now get results for comparison\n",
    "    orig_var = var_es_results[portfolio]['GaussianCopula']['VaR']\n",
    "    orig_es = var_es_results[portfolio]['GaussianCopula']['ES']\n",
    "    rp_var = risk_parity_var_es[portfolio]['VaR']\n",
    "    rp_es = risk_parity_var_es[portfolio]['ES']\n",
    "\n",
    "    # Calculate percentage changes\n",
    "    var_change = (rp_var - orig_var) / orig_var * 100\n",
    "    es_change = (rp_es - orig_es) / orig_es * 100\n",
    "\n",
    "    print(f\"{portfolio:<10} {orig_var*100:<15.4f}% {orig_es*100:<15.4f}% {rp_var*100:<15.4f}% {rp_es*100:<15.4f}% {var_change:<15.2f}% {es_change:<15.2f}%\")\n",
    "\n",
    "# Step 8: Print risk parity portfolio weights\n",
    "print(\"\\nRisk Parity Portfolio Weights:\")\n",
    "print(\"=\" * 100)\n",
    "for portfolio in portfolios:\n",
    "    print(f\"\\nPortfolio {portfolio}:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Symbol':<8} {'Original Weight':<20} {'Risk Parity Weight':<20} {'Change':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    # Get original weights\n",
    "    for symbol in risk_parity_weights[portfolio]:\n",
    "        orig_weight = portfolio_weights[portfolio][symbol]['weight']\n",
    "        rp_weight = risk_parity_weights[portfolio][symbol]\n",
    "        weight_change = rp_weight - orig_weight\n",
    "\n",
    "        print(f\"{symbol:<8} {orig_weight*100:<19.2f}% {rp_weight*100:<19.2f}% {weight_change*100:+<14.2f}%\")\n",
    "\n",
    "# Step 9: Calculate and print risk contributions\n",
    "print(\"\\nRisk Contributions Analysis:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for portfolio in portfolios:\n",
    "    print(f\"\\nPortfolio {portfolio} - Risk Contributions:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Symbol':<8} {'Risk Parity Weight':<20} {'Marginal Contribution':<25} {'% of Total Risk':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Calculate marginal risk contributions using the portfolio's simulation count\n",
    "    mrc = calculate_marginal_risk_contributions(\n",
    "        risk_parity_weights[portfolio],\n",
    "        portfolio,\n",
    "        confidence_level=0.95,\n",
    "        n_simulations=portfolio_params[portfolio]['n_sim']\n",
    "    )\n",
    "\n",
    "    # Calculate risk contributions\n",
    "    rc = {symbol: risk_parity_weights[portfolio][symbol] * mrc[symbol] for symbol in risk_parity_weights[portfolio]}\n",
    "    total_rc = sum(rc.values())\n",
    "\n",
    "    # Print results\n",
    "    for symbol in risk_parity_weights[portfolio]:\n",
    "        rc_pct = rc[symbol] / total_rc * 100\n",
    "\n",
    "        print(f\"{symbol:<8} {risk_parity_weights[portfolio][symbol]*100:<19.2f}% {mrc[symbol]:<24.4f} {rc_pct:<19.2f}%\")\n",
    "\n",
    "    # Verify risk parity: all assets should have approximately equal risk contribution percentages\n",
    "    avg_rc_pct = 100 / len(risk_parity_weights[portfolio])\n",
    "    rc_pcts = [rc[symbol] / total_rc * 100 for symbol in risk_parity_weights[portfolio]]\n",
    "    max_deviation = max([abs(pct - avg_rc_pct) for pct in rc_pcts])\n",
    "\n",
    "    print(f\"\\nTarget risk contribution per asset: {avg_rc_pct:.2f}%\")\n",
    "    print(f\"Maximum deviation from target: {max_deviation:.2f}%\")\n",
    "\n",
    "    # Much more relaxed condition for risk parity achievement for A and B\n",
    "    if max_deviation <= 2.0:\n",
    "        print(\"✓ Risk parity achieved (all assets contribute approximately equally to risk)\")\n",
    "    else:\n",
    "        print(\"⚠ Risk parity not fully achieved - may need more optimization iterations\")\n",
    "\n"
   ],
   "id": "68d9ab3725a4f6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Risk Parity Portfolios ===\n",
      "Using multi-start optimization for portfolio A with 5000 simulations\n",
      "Optimizing portfolio A with 3 different starting points...\n",
      "Attempt 1/3 for portfolio A...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.00034125399500475586\n",
      "            Iterations: 6\n",
      "            Function evaluations: 211\n",
      "            Gradient evaluations: 6\n",
      "Attempt 1 completed in 2.34 seconds with objective value: 0.000341\n",
      "New best result found in attempt 1 with objective value: 0.000341\n",
      "Attempt 2/3 for portfolio A...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 2.161107646556641e-05\n",
      "            Iterations: 12\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 12\n",
      "Attempt 2 completed in 4.78 seconds with objective value: 0.000022\n",
      "New best result found in attempt 2 with objective value: 0.000022\n",
      "Attempt 3/3 for portfolio A...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.00038162456178910363\n",
      "            Iterations: 25\n",
      "            Function evaluations: 887\n",
      "            Gradient evaluations: 25\n",
      "Attempt 3 completed in 10.03 seconds with objective value: 0.000382\n",
      "Best optimization result for portfolio A with objective value: 0.000022\n",
      "Using multi-start optimization for portfolio B with 5000 simulations\n",
      "Optimizing portfolio B with 3 different starting points...\n",
      "Attempt 1/3 for portfolio B...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 9.71374030619512e-05\n",
      "            Iterations: 3\n",
      "            Function evaluations: 106\n",
      "            Gradient evaluations: 3\n",
      "Attempt 1 completed in 1.24 seconds with objective value: 0.000097\n",
      "New best result found in attempt 1 with objective value: 0.000097\n",
      "Attempt 2/3 for portfolio B...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 7.239737404102491e-05\n",
      "            Iterations: 7\n",
      "            Function evaluations: 249\n",
      "            Gradient evaluations: 7\n",
      "Attempt 2 completed in 2.82 seconds with objective value: 0.000072\n",
      "New best result found in attempt 2 with objective value: 0.000072\n",
      "Attempt 3/3 for portfolio B...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 8.293305152364943e-06\n",
      "            Iterations: 11\n",
      "            Function evaluations: 386\n",
      "            Gradient evaluations: 11\n",
      "Attempt 3 completed in 4.20 seconds with objective value: 0.000008\n",
      "New best result found in attempt 3 with objective value: 0.000008\n",
      "Best optimization result for portfolio B with objective value: 0.000008\n",
      "Using multi-start optimization for portfolio C with 5000 simulations\n",
      "Optimizing portfolio C with 3 different starting points...\n",
      "Attempt 1/3 for portfolio C...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.00034033699621709217\n",
      "            Iterations: 6\n",
      "            Function evaluations: 211\n",
      "            Gradient evaluations: 6\n",
      "Attempt 1 completed in 2.30 seconds with objective value: 0.000340\n",
      "New best result found in attempt 1 with objective value: 0.000340\n",
      "Attempt 2/3 for portfolio C...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 4.9044184678972425e-05\n",
      "            Iterations: 8\n",
      "            Function evaluations: 282\n",
      "            Gradient evaluations: 8\n",
      "Attempt 2 completed in 3.12 seconds with objective value: 0.000049\n",
      "New best result found in attempt 2 with objective value: 0.000049\n",
      "Attempt 3/3 for portfolio C...\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1.7050208769296817e-05\n",
      "            Iterations: 17\n",
      "            Function evaluations: 600\n",
      "            Gradient evaluations: 17\n",
      "Attempt 3 completed in 6.54 seconds with objective value: 0.000017\n",
      "New best result found in attempt 3 with objective value: 0.000017\n",
      "Best optimization result for portfolio C with objective value: 0.000017\n",
      "\n",
      "=== Risk Metrics for Risk Parity Portfolios ===\n",
      "\n",
      "Comparison of Original vs Risk Parity Portfolios:\n",
      "====================================================================================================\n",
      "Portfolio  Original VaR    Original ES     RP VaR          RP ES           VaR Change %    ES Change %    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "A          1.3671         % 1.8482         % 1.1963         % 1.5207         % -12.49         % -17.72         %\n",
      "B          1.2399         % 1.7007         % 1.2041         % 1.5132         % -2.89          % -11.03         %\n",
      "C          1.5236         % 2.1319         % 1.2158         % 1.5391         % -20.20         % -27.81         %\n",
      "\n",
      "Risk Parity Portfolio Weights:\n",
      "====================================================================================================\n",
      "\n",
      "Portfolio A:\n",
      "--------------------------------------------------\n",
      "Symbol   Original Weight      Risk Parity Weight   Change         \n",
      "-----------------------------------------------------------------\n",
      "WFC      4.70               % 1.92               % -2.78+++++++++%\n",
      "ETN      0.99               % 2.70               % 1.71++++++++++%\n",
      "AMZN     1.52               % 2.49               % 0.97++++++++++%\n",
      "QCOM     2.12               % 1.77               % -0.35+++++++++%\n",
      "LMT      0.70               % 5.17               % 4.47++++++++++%\n",
      "KO       5.43               % 5.44               % 0.01++++++++++%\n",
      "JNJ      2.35               % 5.07               % 2.72++++++++++%\n",
      "ISRG     0.63               % 2.36               % 1.73++++++++++%\n",
      "XOM      3.11               % 3.14               % 0.02++++++++++%\n",
      "MDT      4.14               % 3.22               % -0.92+++++++++%\n",
      "DHR      1.46               % 2.65               % 1.19++++++++++%\n",
      "PLD      3.18               % 2.12               % -1.06+++++++++%\n",
      "BA       1.99               % 2.67               % 0.69++++++++++%\n",
      "PG       2.05               % 6.19               % 4.13++++++++++%\n",
      "MRK      3.38               % 6.64               % 3.26++++++++++%\n",
      "AMD      2.68               % 1.84               % -0.84+++++++++%\n",
      "BX       1.92               % 1.44               % -0.48+++++++++%\n",
      "PM       2.75               % 3.77               % 1.03++++++++++%\n",
      "SCHW     4.50               % 1.46               % -3.04+++++++++%\n",
      "VZ       8.31               % 4.50               % -3.80+++++++++%\n",
      "COP      3.31               % 3.00               % -0.31+++++++++%\n",
      "ADI      1.56               % 2.23               % 0.67++++++++++%\n",
      "BAC      7.48               % 1.91               % -5.57+++++++++%\n",
      "NOW      0.33               % 2.24               % 1.91++++++++++%\n",
      "TMO      0.63               % 2.64               % 2.01++++++++++%\n",
      "CVX      2.28               % 3.13               % 0.84++++++++++%\n",
      "ANET     2.91               % 2.07               % -0.85+++++++++%\n",
      "NVDA     2.32               % 2.17               % -0.15+++++++++%\n",
      "GE       1.95               % 3.56               % 1.61++++++++++%\n",
      "GILD     3.67               % 3.75               % 0.08++++++++++%\n",
      "MU       3.74               % 2.38               % -1.36+++++++++%\n",
      "CMCSA    8.90               % 2.43               % -6.47+++++++++%\n",
      "DIS      3.01               % 1.92               % -1.09+++++++++%\n",
      "\n",
      "Portfolio B:\n",
      "--------------------------------------------------\n",
      "Symbol   Original Weight      Risk Parity Weight   Change         \n",
      "-----------------------------------------------------------------\n",
      "AXP      1.46               % 2.08               % 0.63++++++++++%\n",
      "HON      1.93               % 2.58               % 0.65++++++++++%\n",
      "META     0.73               % 2.46               % 1.74++++++++++%\n",
      "NFLX     0.51               % 2.06               % 1.55++++++++++%\n",
      "PGR      1.80               % 3.55               % 1.75++++++++++%\n",
      "LLY      0.56               % 4.77               % 4.22++++++++++%\n",
      "JPM      1.80               % 2.83               % 1.04++++++++++%\n",
      "VRTX     1.07               % 3.89               % 2.82++++++++++%\n",
      "TJX      3.60               % 3.94               % 0.35++++++++++%\n",
      "EQIX     0.47               % 2.40               % 1.92++++++++++%\n",
      "AAPL     1.80               % 2.82               % 1.02++++++++++%\n",
      "FI       2.10               % 2.73               % 0.63++++++++++%\n",
      "DE       1.03               % 2.42               % 1.39++++++++++%\n",
      "SBUX     4.71               % 2.58               % -2.13+++++++++%\n",
      "GOOGL    2.27               % 2.56               % 0.29++++++++++%\n",
      "T        19.10              % 3.59               % -15.51++++++++%\n",
      "ABT      3.81               % 4.00               % 0.18++++++++++%\n",
      "BMY      7.67               % 4.02               % -3.64+++++++++%\n",
      "MS       3.47               % 2.24               % -1.23+++++++++%\n",
      "CRM      1.33               % 2.84               % 1.52++++++++++%\n",
      "PFE      16.27              % 3.37               % -12.90++++++++%\n",
      "SPGI     0.90               % 1.97               % 1.07++++++++++%\n",
      "BRK-B    0.99               % 3.39               % 2.40++++++++++%\n",
      "ADBE     1.03               % 1.80               % 0.77++++++++++%\n",
      "ACN      1.24               % 2.65               % 1.41++++++++++%\n",
      "AMGN     1.67               % 3.87               % 2.20++++++++++%\n",
      "LIN      1.07               % 3.22               % 2.15++++++++++%\n",
      "V        1.41               % 3.51               % 2.10++++++++++%\n",
      "WMT      4.80               % 4.58               % -0.22+++++++++%\n",
      "AMAT     2.57               % 2.47               % -0.10+++++++++%\n",
      "CAT      1.20               % 2.27               % 1.07++++++++++%\n",
      "RTX      3.77               % 3.05               % -0.72+++++++++%\n",
      "UNP      1.88               % 3.47               % 1.58++++++++++%\n",
      "\n",
      "Portfolio C:\n",
      "--------------------------------------------------\n",
      "Symbol   Original Weight      Risk Parity Weight   Change         \n",
      "-----------------------------------------------------------------\n",
      "IBM      2.37               % 4.64               % 2.26++++++++++%\n",
      "TXN      2.78               % 2.24               % -0.54+++++++++%\n",
      "ADP      1.81               % 2.54               % 0.73++++++++++%\n",
      "GOOG     2.73               % 2.34               % -0.39+++++++++%\n",
      "ORCL     3.15               % 2.06               % -1.08+++++++++%\n",
      "BSX      5.78               % 3.80               % -1.98+++++++++%\n",
      "UNH      1.03               % 5.67               % 4.64++++++++++%\n",
      "TMUS     2.42               % 4.85               % 2.43++++++++++%\n",
      "SYK      1.44               % 2.92               % 1.48++++++++++%\n",
      "GS       0.93               % 2.47               % 1.54++++++++++%\n",
      "UBER     8.10               % 2.10               % -5.99+++++++++%\n",
      "AVGO     2.27               % 2.31               % 0.04++++++++++%\n",
      "MMC      2.48               % 3.18               % 0.70++++++++++%\n",
      "CSCO     8.87               % 2.53               % -6.34+++++++++%\n",
      "PLTR     6.55               % 1.20               % -5.35+++++++++%\n",
      "MA       1.03               % 2.96               % 1.93++++++++++%\n",
      "C        7.37               % 2.44               % -4.94+++++++++%\n",
      "BKNG     0.15               % 2.94               % 2.79++++++++++%\n",
      "MCD      1.81               % 4.82               % 3.01++++++++++%\n",
      "LOW      2.11               % 2.69               % 0.58++++++++++%\n",
      "HD       1.34               % 2.71               % 1.37++++++++++%\n",
      "INTU     0.88               % 1.72               % 0.85++++++++++%\n",
      "LRCX     6.96               % 2.02               % -4.95+++++++++%\n",
      "KKR      3.46               % 1.74               % -1.71+++++++++%\n",
      "COST     0.62               % 3.95               % 3.33++++++++++%\n",
      "NEE      7.27               % 2.28               % -4.99+++++++++%\n",
      "ABBV     2.89               % 5.65               % 2.76++++++++++%\n",
      "TSLA     1.29               % 1.69               % 0.40++++++++++%\n",
      "MSFT     1.24               % 3.06               % 1.82++++++++++%\n",
      "PEP      3.51               % 5.32               % 1.81++++++++++%\n",
      "CB       1.96               % 4.39               % 2.43++++++++++%\n",
      "PANW     2.89               % 2.21               % -0.67+++++++++%\n",
      "BLK      0.52               % 2.54               % 2.03++++++++++%\n",
      "\n",
      "Risk Contributions Analysis:\n",
      "====================================================================================================\n",
      "\n",
      "Portfolio A - Risk Contributions:\n",
      "----------------------------------------------------------------------\n",
      "Symbol   Risk Parity Weight   Marginal Contribution     % of Total Risk     \n",
      "----------------------------------------------------------------------\n",
      "WFC      1.92               % 1.5595                   3.00               %\n",
      "ETN      2.70               % 1.1747                   3.18               %\n",
      "AMZN     2.49               % 1.2468                   3.11               %\n",
      "QCOM     1.77               % 1.7258                   3.05               %\n",
      "LMT      5.17               % 0.6021                   3.11               %\n",
      "KO       5.44               % 0.5465                   2.97               %\n",
      "JNJ      5.07               % 0.6100                   3.09               %\n",
      "ISRG     2.36               % 1.3585                   3.20               %\n",
      "XOM      3.14               % 0.9323                   2.92               %\n",
      "MDT      3.22               % 0.9202                   2.96               %\n",
      "DHR      2.65               % 1.0983                   2.91               %\n",
      "PLD      2.12               % 1.4254                   3.02               %\n",
      "BA       2.67               % 1.1442                   3.06               %\n",
      "PG       6.19               % 0.4827                   2.99               %\n",
      "MRK      6.64               % 0.4575                   3.04               %\n",
      "AMD      1.84               % 1.6426                   3.02               %\n",
      "BX       1.44               % 1.9845                   2.86               %\n",
      "PM       3.77               % 0.8127                   3.07               %\n",
      "SCHW     1.46               % 2.0175                   2.94               %\n",
      "VZ       4.50               % 0.6858                   3.09               %\n",
      "COP      3.00               % 1.0085                   3.02               %\n",
      "ADI      2.23               % 1.3594                   3.03               %\n",
      "BAC      1.91               % 1.5687                   3.00               %\n",
      "NOW      2.24               % 1.3659                   3.06               %\n",
      "TMO      2.64               % 1.1764                   3.10               %\n",
      "CVX      3.13               % 0.9607                   3.00               %\n",
      "ANET     2.07               % 1.4695                   3.03               %\n",
      "NVDA     2.17               % 1.3797                   2.99               %\n",
      "GE       3.56               % 0.9102                   3.24               %\n",
      "GILD     3.75               % 0.8027                   3.01               %\n",
      "MU       2.38               % 1.2535                   2.99               %\n",
      "CMCSA    2.43               % 1.2242                   2.98               %\n",
      "DIS      1.92               % 1.5276                   2.94               %\n",
      "\n",
      "Target risk contribution per asset: 3.03%\n",
      "Maximum deviation from target: 0.21%\n",
      "✓ Risk parity achieved (all assets contribute approximately equally to risk)\n",
      "\n",
      "Portfolio B - Risk Contributions:\n",
      "----------------------------------------------------------------------\n",
      "Symbol   Risk Parity Weight   Marginal Contribution     % of Total Risk     \n",
      "----------------------------------------------------------------------\n",
      "AXP      2.08               % 1.4485                   3.02               %\n",
      "HON      2.58               % 1.1664                   3.01               %\n",
      "META     2.46               % 1.2431                   3.06               %\n",
      "NFLX     2.06               % 1.4857                   3.06               %\n",
      "PGR      3.55               % 0.8736                   3.10               %\n",
      "LLY      4.77               % 0.6292                   3.00               %\n",
      "JPM      2.83               % 1.0816                   3.07               %\n",
      "VRTX     3.89               % 0.7725                   3.00               %\n",
      "TJX      3.94               % 0.7481                   2.95               %\n",
      "EQIX     2.40               % 1.2352                   2.96               %\n",
      "AAPL     2.82               % 1.0623                   3.00               %\n",
      "FI       2.73               % 1.1002                   3.00               %\n",
      "DE       2.42               % 1.2281                   2.98               %\n",
      "SBUX     2.58               % 1.1595                   2.99               %\n",
      "GOOGL    2.56               % 1.2307                   3.15               %\n",
      "T        3.59               % 0.8529                   3.06               %\n",
      "ABT      4.00               % 0.7731                   3.09               %\n",
      "BMY      4.02               % 0.7633                   3.07               %\n",
      "MS       2.24               % 1.3319                   2.98               %\n",
      "CRM      2.84               % 1.0785                   3.07               %\n",
      "PFE      3.37               % 0.9047                   3.05               %\n",
      "SPGI     1.97               % 1.5445                   3.05               %\n",
      "BRK-B    3.39               % 0.8978                   3.04               %\n",
      "ADBE     1.80               % 1.6619                   2.99               %\n",
      "ACN      2.65               % 1.1344                   3.00               %\n",
      "AMGN     3.87               % 0.7775                   3.01               %\n",
      "LIN      3.22               % 0.9334                   3.00               %\n",
      "V        3.51               % 0.8592                   3.02               %\n",
      "WMT      4.58               % 0.6415                   2.94               %\n",
      "AMAT     2.47               % 1.2326                   3.04               %\n",
      "CAT      2.27               % 1.3206                   2.99               %\n",
      "RTX      3.05               % 1.0100                   3.08               %\n",
      "UNP      3.47               % 0.9069                   3.15               %\n",
      "\n",
      "Target risk contribution per asset: 3.03%\n",
      "Maximum deviation from target: 0.12%\n",
      "✓ Risk parity achieved (all assets contribute approximately equally to risk)\n",
      "\n",
      "Portfolio C - Risk Contributions:\n",
      "----------------------------------------------------------------------\n",
      "Symbol   Risk Parity Weight   Marginal Contribution     % of Total Risk     \n",
      "----------------------------------------------------------------------\n",
      "IBM      4.64               % 0.6801                   3.15               %\n",
      "TXN      2.24               % 1.3640                   3.06               %\n",
      "ADP      2.54               % 1.2464                   3.16               %\n",
      "GOOG     2.34               % 1.2992                   3.04               %\n",
      "ORCL     2.06               % 1.4514                   3.00               %\n",
      "BSX      3.80               % 0.7969                   3.03               %\n",
      "UNH      5.67               % 0.5447                   3.09               %\n",
      "TMUS     4.85               % 0.6447                   3.13               %\n",
      "SYK      2.92               % 1.0243                   2.99               %\n",
      "GS       2.47               % 1.2140                   2.99               %\n",
      "UBER     2.10               % 1.4330                   3.01               %\n",
      "AVGO     2.31               % 1.2869                   2.97               %\n",
      "MMC      3.18               % 0.9671                   3.07               %\n",
      "CSCO     2.53               % 1.2025                   3.04               %\n",
      "PLTR     1.20               % 2.4976                   2.99               %\n",
      "MA       2.96               % 1.0121                   3.00               %\n",
      "C        2.44               % 1.2387                   3.02               %\n",
      "BKNG     2.94               % 0.9905                   2.92               %\n",
      "MCD      4.82               % 0.6311                   3.04               %\n",
      "LOW      2.69               % 1.1622                   3.13               %\n",
      "HD       2.71               % 1.1648                   3.15               %\n",
      "INTU     1.72               % 1.7158                   2.96               %\n",
      "LRCX     2.02               % 1.4808                   2.98               %\n",
      "KKR      1.74               % 1.6626                   2.90               %\n",
      "COST     3.95               % 0.7909                   3.13               %\n",
      "NEE      2.28               % 1.3169                   3.01               %\n",
      "ABBV     5.65               % 0.5138                   2.90               %\n",
      "TSLA     1.69               % 1.7287                   2.93               %\n",
      "MSFT     3.06               % 0.9669                   2.96               %\n",
      "PEP      5.32               % 0.5805                   3.09               %\n",
      "CB       4.39               % 0.6920                   3.04               %\n",
      "PANW     2.21               % 1.3721                   3.04               %\n",
      "BLK      2.54               % 1.2102                   3.08               %\n",
      "\n",
      "Target risk contribution per asset: 3.03%\n",
      "Maximum deviation from target: 0.13%\n",
      "✓ Risk parity achieved (all assets contribute approximately equally to risk)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T02:08:51.798884Z",
     "start_time": "2025-04-19T02:08:51.438220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import problem1\n",
    "import problem2\n",
    "\n",
    "# Step 10: Calculate return attribution for risk parity portfolios\n",
    "\n",
    "# First, get all the necessary data from problem1\n",
    "print(\"\\nProblem 1:\")\n",
    "capm_results = problem1.run_capm_analysis()\n",
    "print(\"\\nProblem 2:\")\n",
    "# Also get results from problem2\n",
    "sharpe_results = problem2.run_optimal_sharpe_analysis()\n",
    "print(\"\\nProblem 5:\")\n",
    "\n",
    "\n",
    "# Read necessary data files\n",
    "daily_prices = pd.read_csv('../Projects/Final Project/DailyPrices.csv')\n",
    "rf_data = pd.read_csv('../Projects/Final Project/rf.csv')\n",
    "\n",
    "# Data preprocessing\n",
    "daily_prices['Date'] = pd.to_datetime(daily_prices['Date'])\n",
    "daily_prices.set_index('Date', inplace=True)\n",
    "\n",
    "rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "rf_data.set_index('Date', inplace=True)\n",
    "\n",
    "# Find the end of 2023\n",
    "end_of_2023 = daily_prices[daily_prices.index.year == 2023].index.max()\n",
    "last_date = daily_prices.index.max()\n",
    "\n",
    "# Extract necessary prices\n",
    "end_of_2023_prices = daily_prices.loc[end_of_2023]\n",
    "last_day_prices = daily_prices.loc[last_date]\n",
    "\n",
    "# Get CAPM parameters\n",
    "capm_params = capm_results['capm_params']\n",
    "\n",
    "# Calculate stock simple returns (already done in problem1 and problem2, but for completeness)\n",
    "stock_simple_returns = {}\n",
    "for symbol in daily_prices.columns:\n",
    "    if symbol in end_of_2023_prices and symbol in last_day_prices:\n",
    "        initial_price = end_of_2023_prices[symbol]\n",
    "        final_price = last_day_prices[symbol]\n",
    "        if not np.isnan(initial_price) and not np.isnan(final_price) and initial_price > 0:\n",
    "            stock_simple_returns[symbol] = (final_price - initial_price) / initial_price\n",
    "        else:\n",
    "            stock_simple_returns[symbol] = np.nan\n",
    "\n",
    "# Market return (SPY)\n",
    "spy_return = stock_simple_returns['SPY']\n",
    "\n",
    "# Get risk-free return\n",
    "test_rf = rf_data.loc[rf_data.index > end_of_2023].squeeze()\n",
    "test_rf_return = (1 + test_rf).prod() - 1\n",
    "\n",
    "# Create a structure similar to initial_portfolio but with risk parity weights\n",
    "rp_holdings = []\n",
    "for portfolio_name in risk_parity_weights:\n",
    "    for symbol, weight in risk_parity_weights[portfolio_name].items():\n",
    "        # Calculate new holdings based on portfolio value\n",
    "        portfolio_value = capm_results['portfolio_values'][portfolio_name]['initial_value']\n",
    "        symbol_price = end_of_2023_prices[symbol]\n",
    "        holding = (portfolio_value * weight) / symbol_price\n",
    "        rp_holdings.append({\n",
    "            'Portfolio': portfolio_name,\n",
    "            'Symbol': symbol,\n",
    "            'Holding': holding\n",
    "        })\n",
    "\n",
    "rp_portfolio_df = pd.DataFrame(rp_holdings)\n",
    "\n",
    "# Calculate risk parity portfolio values and returns\n",
    "rp_portfolio_values = {}\n",
    "\n",
    "for portfolio_name in risk_parity_weights:\n",
    "    portfolio_stocks = rp_portfolio_df[rp_portfolio_df['Portfolio'] == portfolio_name]\n",
    "\n",
    "    initial_stock_values = {}\n",
    "    final_stock_values = {}\n",
    "    total_initial_value = 0\n",
    "    total_final_value = 0\n",
    "\n",
    "    # Calculate portfolio beta\n",
    "    portfolio_beta = 0\n",
    "\n",
    "    for _, row in portfolio_stocks.iterrows():\n",
    "        symbol = row['Symbol']\n",
    "        holding = row['Holding']\n",
    "\n",
    "        if (symbol in end_of_2023_prices and not np.isnan(end_of_2023_prices[symbol]) and\n",
    "            symbol in last_day_prices and not np.isnan(last_day_prices[symbol])):\n",
    "\n",
    "            initial_value = holding * end_of_2023_prices[symbol]\n",
    "            final_value = holding * last_day_prices[symbol]\n",
    "\n",
    "            initial_stock_values[symbol] = initial_value\n",
    "            final_stock_values[symbol] = final_value\n",
    "\n",
    "            total_initial_value += initial_value\n",
    "            total_final_value += final_value\n",
    "\n",
    "    # Recalculate portfolio beta\n",
    "    portfolio_beta = 0\n",
    "    for symbol, initial_value in initial_stock_values.items():\n",
    "        if symbol in capm_params:\n",
    "            stock_beta = capm_params[symbol]['beta']\n",
    "        else:\n",
    "            stock_beta = 0\n",
    "\n",
    "        portfolio_beta += (initial_value / total_initial_value) * stock_beta if total_initial_value > 0 else 0\n",
    "\n",
    "    # Calculate simple return\n",
    "    simple_return = (total_final_value - total_initial_value) / total_initial_value if total_initial_value > 0 else 0\n",
    "\n",
    "    rp_portfolio_values[portfolio_name] = {\n",
    "        'initial_value': total_initial_value,\n",
    "        'final_value': total_final_value,\n",
    "        'simple_return': simple_return,\n",
    "        'initial_stock_values': initial_stock_values,\n",
    "        'final_stock_values': final_stock_values,\n",
    "        'portfolio_beta': portfolio_beta\n",
    "    }\n",
    "\n",
    "# Calculate return attribution for risk parity portfolios\n",
    "rp_portfolio_attributions = {}\n",
    "\n",
    "for portfolio_name, portfolio_values_data in rp_portfolio_values.items():\n",
    "    total_return = portfolio_values_data['simple_return']\n",
    "    portfolio_beta = portfolio_values_data['portfolio_beta']\n",
    "\n",
    "    # Calculate return attribution\n",
    "    systematic_return = portfolio_beta * spy_return\n",
    "    idiosyncratic_return = total_return - systematic_return\n",
    "\n",
    "    # Store attribution results\n",
    "    rp_portfolio_attributions[portfolio_name] = {\n",
    "        'total_return': total_return,\n",
    "        'rf_return': test_rf_return,\n",
    "        'systematic_return': systematic_return,\n",
    "        'idiosyncratic_return': idiosyncratic_return,\n",
    "        'total_excess_return': total_return - test_rf_return,\n",
    "        'portfolio_beta': portfolio_beta\n",
    "    }\n",
    "\n",
    "# Calculate total risk parity portfolio attribution\n",
    "total_rp_initial_value = sum(pv['initial_value'] for pv in rp_portfolio_values.values())\n",
    "total_rp_final_value = sum(pv['final_value'] for pv in rp_portfolio_values.values())\n",
    "\n",
    "# Calculate total simple return\n",
    "total_rp_simple_return = (total_rp_final_value - total_rp_initial_value) / total_rp_initial_value if total_rp_initial_value > 0 else 0\n",
    "\n",
    "# Calculate total portfolio beta\n",
    "total_rp_portfolio_beta = 0\n",
    "for portfolio_name, portfolio_data in rp_portfolio_values.items():\n",
    "    weight = portfolio_data['initial_value'] / total_rp_initial_value\n",
    "    total_rp_portfolio_beta += weight * portfolio_data['portfolio_beta']\n",
    "\n",
    "# Calculate total return attribution\n",
    "total_rp_systematic_return = total_rp_portfolio_beta * spy_return\n",
    "total_rp_idiosyncratic_return = total_rp_simple_return - total_rp_systematic_return\n",
    "\n",
    "total_rp_portfolio_attribution = {\n",
    "    'total_return': total_rp_simple_return,\n",
    "    'rf_return': test_rf_return,\n",
    "    'systematic_return': total_rp_systematic_return,\n",
    "    'idiosyncratic_return': total_rp_idiosyncratic_return,\n",
    "    'total_excess_return': total_rp_simple_return - test_rf_return,\n",
    "    'portfolio_beta': total_rp_portfolio_beta,\n",
    "    'weights': {}\n",
    "}\n",
    "\n",
    "def calculate_volatility_attribution(portfolio_weights, portfolio_name, stock_returns, market_symbol='SPY'):\n",
    "    \"\"\"\n",
    "    计算投资组合的波动率归因\n",
    "\n",
    "    Args:\n",
    "        portfolio_weights: 投资组合权重字典\n",
    "        portfolio_name: 投资组合名称\n",
    "        stock_returns: 股票收益率数据\n",
    "        market_symbol: 市场指数符号，默认为SPY\n",
    "\n",
    "    Returns:\n",
    "        字典，包含系统性风险、特异性风险和总风险\n",
    "    \"\"\"\n",
    "    # 收集投资组合中股票的回报率\n",
    "    portfolio_symbols = list(portfolio_weights.keys())\n",
    "    returns_data = {symbol: stock_returns[symbol] for symbol in portfolio_symbols if symbol in stock_returns}\n",
    "\n",
    "    # 计算投资组合回报率\n",
    "    portfolio_returns = np.zeros(len(stock_returns[market_symbol]))\n",
    "    for symbol, weight in portfolio_weights.items():\n",
    "        if symbol in stock_returns:\n",
    "            portfolio_returns += weight * stock_returns[symbol]\n",
    "\n",
    "    # 计算投资组合总波动率\n",
    "    portfolio_volatility = np.std(portfolio_returns)\n",
    "\n",
    "    # 计算市场回报率与投资组合回报率的相关性\n",
    "    market_returns = stock_returns[market_symbol]\n",
    "\n",
    "    # 运行单因子回归 R_p = α + β * R_m + ε\n",
    "    X = market_returns.reshape(-1, 1)\n",
    "    y = portfolio_returns\n",
    "\n",
    "    # 添加常数项\n",
    "    X_with_const = np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "    # 最小二乘法计算系数\n",
    "    beta_alpha = np.linalg.lstsq(X_with_const, y, rcond=None)[0]\n",
    "    alpha = beta_alpha[0]\n",
    "    beta = beta_alpha[1]\n",
    "\n",
    "    # 计算拟合值和残差\n",
    "    fitted_returns = alpha + beta * market_returns\n",
    "    residuals = portfolio_returns - fitted_returns\n",
    "\n",
    "    # 计算系统性风险（β * σ_m）\n",
    "    market_volatility = np.std(market_returns)\n",
    "    systematic_risk = beta * market_volatility\n",
    "\n",
    "    # 计算特异性风险（残差波动率）\n",
    "    idiosyncratic_risk = np.std(residuals)\n",
    "\n",
    "    # 验证：总风险²应约等于系统性风险²+特异性风险²\n",
    "    # portfolio_variance = systematic_risk**2 + idiosyncratic_risk**2\n",
    "\n",
    "    return {\n",
    "        'spy': systematic_risk,\n",
    "        'alpha': idiosyncratic_risk,\n",
    "        'portfolio': portfolio_volatility\n",
    "    }\n",
    "\n",
    "# Calculate weights of each portfolio in the total\n",
    "for portfolio_name, portfolio_data in rp_portfolio_values.items():\n",
    "    weight = portfolio_data['initial_value'] / total_rp_initial_value\n",
    "    total_rp_portfolio_attribution['weights'][portfolio_name] = weight\n",
    "\n",
    "# Calculate volatility attribution for risk parity portfolios (simplified)\n",
    "rp_vol_attribution = {}\n",
    "\n",
    "# 处理每个子投资组合\n",
    "for portfolio_name in portfolios:\n",
    "    rp_vol_attribution[portfolio_name] = calculate_volatility_attribution(\n",
    "        risk_parity_weights[portfolio_name],\n",
    "        portfolio_name,\n",
    "        stock_returns\n",
    "    )\n",
    "\n",
    "# 计算总体投资组合的风险归因\n",
    "# 首先合并所有风险平价投资组合的权重\n",
    "total_rp_weights = {}\n",
    "for portfolio_name, weights in risk_parity_weights.items():\n",
    "    portfolio_weight = total_rp_portfolio_attribution['weights'][portfolio_name]\n",
    "    for symbol, weight in weights.items():\n",
    "        if symbol in total_rp_weights:\n",
    "            total_rp_weights[symbol] += weight * portfolio_weight\n",
    "        else:\n",
    "            total_rp_weights[symbol] = weight * portfolio_weight\n",
    "\n",
    "# 计算总体投资组合的风险归因\n",
    "rp_vol_attribution['Total'] = calculate_volatility_attribution(\n",
    "    total_rp_weights,\n",
    "    'Total',\n",
    "    stock_returns\n",
    ")\n",
    "\n",
    "# Print attribution results using format from problem1\n",
    "print(\"\\n\")\n",
    "problem1.print_attribution_results(rp_portfolio_attributions, total_rp_portfolio_attribution,\n",
    "                             stock_simple_returns, rp_vol_attribution)\n",
    "\n",
    "# Step 11: Compare all three strategies\n",
    "print(\"\\n=== Comparison of All Three Portfolio Strategies ===\")\n",
    "\n",
    "# Get original portfolio attribution\n",
    "original_portfolio_attributions = capm_results['portfolio_attributions']\n",
    "original_total_attribution = capm_results['total_portfolio_attribution']\n",
    "\n",
    "# Get optimal Sharpe ratio portfolio attribution\n",
    "sharpe_portfolio_attributions = sharpe_results['optimal_portfolio_attributions']\n",
    "sharpe_total_attribution = sharpe_results['optimal_total_portfolio_attribution']\n",
    "\n",
    "# Create comparison table\n",
    "print(\"\\nTotal Portfolio Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Metric':<20} {'Original':<15} {'Optimal Sharpe':<15} {'Risk Parity':<15} {'OS vs Orig':<15} {'RP vs Orig':<15}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Total return\n",
    "orig_return = original_total_attribution['total_return']\n",
    "sharpe_return = sharpe_total_attribution['total_return']\n",
    "rp_return = total_rp_portfolio_attribution['total_return']\n",
    "print(f\"{'Total Return':<20} {orig_return*100:14.2f}% {sharpe_return*100:14.2f}% {rp_return*100:14.2f}% {(sharpe_return-orig_return)*100:14.2f}% {(rp_return-orig_return)*100:14.2f}%\")\n",
    "\n",
    "# Systematic return\n",
    "orig_sys = original_total_attribution['systematic_return']\n",
    "sharpe_sys = sharpe_total_attribution['systematic_return']\n",
    "rp_sys = total_rp_portfolio_attribution['systematic_return']\n",
    "print(f\"{'Systematic Return':<20} {orig_sys*100:14.2f}% {sharpe_sys*100:14.2f}% {rp_sys*100:14.2f}% {(sharpe_sys-orig_sys)*100:14.2f}% {(rp_sys-orig_sys)*100:14.2f}%\")\n",
    "\n",
    "# Idiosyncratic return\n",
    "orig_idio = original_total_attribution['idiosyncratic_return']\n",
    "sharpe_idio = sharpe_total_attribution['idiosyncratic_return']\n",
    "rp_idio = total_rp_portfolio_attribution['idiosyncratic_return']\n",
    "print(f\"{'Idiosyncratic Return':<20} {orig_idio*100:14.2f}% {sharpe_idio*100:14.2f}% {rp_idio*100:14.2f}% {(sharpe_idio-orig_idio)*100:14.2f}% {(rp_idio-orig_idio)*100:14.2f}%\")\n",
    "\n",
    "# Beta\n",
    "orig_beta = original_total_attribution['portfolio_beta']\n",
    "sharpe_beta = sharpe_total_attribution['portfolio_beta']\n",
    "rp_beta = total_rp_portfolio_attribution['portfolio_beta']\n",
    "print(f\"{'Portfolio Beta':<20} {orig_beta:14.2f} {sharpe_beta:14.2f} {rp_beta:14.2f} {(sharpe_beta-orig_beta):14.2f} {(rp_beta-orig_beta):14.2f}\")\n",
    "\n",
    "# Compare each sub-portfolio\n",
    "for portfolio_name in portfolios:\n",
    "    print(f\"\\nComparison for Portfolio {portfolio_name}:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"{'Metric':<20} {'Original':<15} {'Optimal Sharpe':<15} {'Risk Parity':<15} {'OS vs Orig':<15} {'RP vs Orig':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    orig_return = original_portfolio_attributions[portfolio_name]['total_return']\n",
    "    sharpe_return = sharpe_portfolio_attributions[portfolio_name]['total_return']\n",
    "    rp_return = rp_portfolio_attributions[portfolio_name]['total_return']\n",
    "    print(f\"{'Total Return':<20} {orig_return*100:14.2f}% {sharpe_return*100:14.2f}% {rp_return*100:14.2f}% {(sharpe_return-orig_return)*100:14.2f}% {(rp_return-orig_return)*100:14.2f}%\")\n",
    "\n",
    "    orig_sys = original_portfolio_attributions[portfolio_name]['systematic_return']\n",
    "    sharpe_sys = sharpe_portfolio_attributions[portfolio_name]['systematic_return']\n",
    "    rp_sys = rp_portfolio_attributions[portfolio_name]['systematic_return']\n",
    "    print(f\"{'Systematic Return':<20} {orig_sys*100:14.2f}% {sharpe_sys*100:14.2f}% {rp_sys*100:14.2f}% {(sharpe_sys-orig_sys)*100:14.2f}% {(rp_sys-orig_sys)*100:14.2f}%\")\n",
    "\n",
    "    orig_idio = original_portfolio_attributions[portfolio_name]['idiosyncratic_return']\n",
    "    sharpe_idio = sharpe_portfolio_attributions[portfolio_name]['idiosyncratic_return']\n",
    "    rp_idio = rp_portfolio_attributions[portfolio_name]['idiosyncratic_return']\n",
    "    print(f\"{'Idiosyncratic Return':<20} {orig_idio*100:14.2f}% {sharpe_idio*100:14.2f}% {rp_idio*100:14.2f}% {(sharpe_idio-orig_idio)*100:14.2f}% {(rp_idio-orig_idio)*100:14.2f}%\")\n",
    "\n",
    "    orig_beta = original_portfolio_attributions[portfolio_name]['portfolio_beta']\n",
    "    sharpe_beta = sharpe_portfolio_attributions[portfolio_name]['portfolio_beta']\n",
    "    rp_beta = rp_portfolio_attributions[portfolio_name]['portfolio_beta']\n",
    "    print(f\"{'Portfolio Beta':<20} {orig_beta:14.2f} {sharpe_beta:14.2f} {rp_beta:14.2f} {(sharpe_beta-orig_beta):14.2f} {(rp_beta-orig_beta):14.2f}\")\n",
    "\n",
    "    # Add risk metrics\n",
    "    if portfolio_name in risk_parity_var_es:\n",
    "        orig_var = var_es_results[portfolio_name]['GaussianCopula']['VaR'] * 100\n",
    "        orig_es = var_es_results[portfolio_name]['GaussianCopula']['ES'] * 100\n",
    "        rp_var = risk_parity_var_es[portfolio_name]['VaR'] * 100\n",
    "        rp_es = risk_parity_var_es[portfolio_name]['ES'] * 100\n",
    "\n",
    "        # For Sharpe ratio portfolios, we don't have these metrics, so we'll leave them blank\n",
    "        print(f\"{'VaR (95%)':<20} {orig_var:14.2f}% {'-':>14} {rp_var:14.2f}% {'-':>14} {(rp_var-orig_var):14.2f}%\")\n",
    "        print(f\"{'ES (95%)':<20} {orig_es:14.2f}% {'-':>14} {rp_es:14.2f}% {'-':>14} {(rp_es-orig_es):14.2f}%\")\n",
    "\n",
    "# Step 12: Print a summary of findings\n",
    "print(\"\\n=== Summary of Portfolio Strategy Comparison ===\")\n",
    "print(\"\\nKey Findings:\")\n",
    "\n",
    "# Compare total returns\n",
    "strategies = [\"Original\", \"Optimal Sharpe\", \"Risk Parity\"]\n",
    "returns = [orig_return*100, sharpe_return*100, rp_return*100]\n",
    "best_return_idx = returns.index(max(returns))\n",
    "print(f\"1. Best overall return: {strategies[best_return_idx]} portfolio with {max(returns):.2f}%\")\n",
    "\n",
    "# Compare systematic risk (beta)\n",
    "betas = [orig_beta, sharpe_beta, rp_beta]\n",
    "lowest_beta_idx = betas.index(min(betas))\n",
    "print(f\"2. Lowest systematic risk (beta): {strategies[lowest_beta_idx]} portfolio with beta of {min(betas):.2f}\")\n",
    "\n",
    "# Compare risk metrics\n",
    "if 'A' in risk_parity_var_es:\n",
    "    print(f\"3. Risk Parity approach reduced risk compared to original portfolio:\")\n",
    "    for portfolio_name in portfolios:\n",
    "        var_change = (risk_parity_var_es[portfolio_name]['VaR'] - var_es_results[portfolio_name]['GaussianCopula']['VaR']) / var_es_results[portfolio_name]['GaussianCopula']['VaR'] * 100\n",
    "        es_change = (risk_parity_var_es[portfolio_name]['ES'] - var_es_results[portfolio_name]['GaussianCopula']['ES']) / var_es_results[portfolio_name]['GaussianCopula']['ES'] * 100\n",
    "\n",
    "        print(f\"   - Portfolio {portfolio_name}: VaR changed by {var_change:.2f}%, ES changed by {es_change:.2f}%\")\n",
    "\n",
    "# Compare idiosyncratic returns\n",
    "idio_returns = [orig_idio*100, sharpe_idio*100, rp_idio*100]\n",
    "best_idio_idx = idio_returns.index(max(idio_returns))\n",
    "print(f\"4. Best idiosyncratic return: {strategies[best_idio_idx]} portfolio with {max(idio_returns):.2f}%\")\n"
   ],
   "id": "10927ef249ef28e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problem 1:\n",
      "开始执行CAPM投资组合风险与收益归因分析...\n",
      "训练集结束日期: 2023-12-29\n",
      "训练集天数: 250\n",
      "测试集天数: 254\n",
      "\n",
      "部分股票的CAPM参数:\n",
      "AAPL: Beta=1.10, Alpha=0.0008, R²=0.53\n",
      "MSFT: Beta=1.17, Alpha=0.0009, R²=0.37\n",
      "AMZN: Beta=1.53, Alpha=0.0011, R²=0.37\n",
      "GOOGL: Beta=1.38, Alpha=0.0007, R²=0.35\n",
      "META: Beta=1.77, Alpha=0.0029, R²=0.34\n",
      "\n",
      "各投资组合价值和简单回报率:\n",
      "A: 初始值=$295444.61, 最终值=$335814.67, 回报率=13.66%, Beta=0.97\n",
      "B: 初始值=$280904.48, 最终值=$338075.80, 回报率=20.35%, Beta=0.92\n",
      "C: 初始值=$267591.44, 最终值=$342830.78, 回报率=28.12%, Beta=0.97\n",
      "\n",
      "主要股票的简单回报率:\n",
      "SPY: 26.14%\n",
      "AAPL: 27.02%\n",
      "MSFT: 13.20%\n",
      "AMZN: 47.55%\n",
      "GOOGL: 37.79%\n",
      "\n",
      "无风险回报率: 5.27%\n",
      "\n",
      "\n",
      "# Total Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.056642      0.204731\n",
      "#  2   | Return Attribution         0.249311     -0.044580      0.204731\n",
      "#  3   | Vol Attribution            0.007221     -0.000135      0.007090\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.124731      0.136642\n",
      "#  2   | Return Attribution         0.252920     -0.116279      0.136642\n",
      "#  3   | Vol Attribution            0.007090      0.000350      0.007418\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.057847      0.203526\n",
      "#  2   | Return Attribution         0.240717     -0.037191      0.203526\n",
      "#  3   | Vol Attribution            0.007150     -0.000250      0.006900\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373      0.019800      0.281172\n",
      "#  2   | Return Attribution         0.254348      0.026824      0.281172\n",
      "#  3   | Vol Attribution            0.007350      0.000450      0.007800\n",
      "\n",
      "Problem 2:\n",
      "开始执行最优夏普比率投资组合分析...\n",
      "开始执行CAPM投资组合风险与收益归因分析...\n",
      "训练集结束日期: 2023-12-29\n",
      "训练集天数: 250\n",
      "测试集天数: 254\n",
      "\n",
      "部分股票的CAPM参数:\n",
      "AAPL: Beta=1.10, Alpha=0.0008, R²=0.53\n",
      "MSFT: Beta=1.17, Alpha=0.0009, R²=0.37\n",
      "AMZN: Beta=1.53, Alpha=0.0011, R²=0.37\n",
      "GOOGL: Beta=1.38, Alpha=0.0007, R²=0.35\n",
      "META: Beta=1.77, Alpha=0.0029, R²=0.34\n",
      "\n",
      "各投资组合价值和简单回报率:\n",
      "A: 初始值=$295444.61, 最终值=$335814.67, 回报率=13.66%, Beta=0.97\n",
      "B: 初始值=$280904.48, 最终值=$338075.80, 回报率=20.35%, Beta=0.92\n",
      "C: 初始值=$267591.44, 最终值=$342830.78, 回报率=28.12%, Beta=0.97\n",
      "\n",
      "主要股票的简单回报率:\n",
      "SPY: 26.14%\n",
      "AAPL: 27.02%\n",
      "MSFT: 13.20%\n",
      "AMZN: 47.55%\n",
      "GOOGL: 37.79%\n",
      "\n",
      "无风险回报率: 5.27%\n",
      "\n",
      "\n",
      "# Total Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.056642      0.204731\n",
      "#  2   | Return Attribution         0.249311     -0.044580      0.204731\n",
      "#  3   | Vol Attribution            0.007221     -0.000135      0.007090\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.124731      0.136642\n",
      "#  2   | Return Attribution         0.252920     -0.116279      0.136642\n",
      "#  3   | Vol Attribution            0.007090      0.000350      0.007418\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.057847      0.203526\n",
      "#  2   | Return Attribution         0.240717     -0.037191      0.203526\n",
      "#  3   | Vol Attribution            0.007150     -0.000250      0.006900\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373      0.019800      0.281172\n",
      "#  2   | Return Attribution         0.254348      0.026824      0.281172\n",
      "#  3   | Vol Attribution            0.007350      0.000450      0.007800\n",
      "\n",
      "股票期望收益率:\n",
      "AAPL: 26.88%\n",
      "MSFT: 28.19%\n",
      "AMZN: 35.39%\n",
      "GOOGL: 32.34%\n",
      "META: 40.03%\n",
      "\n",
      "投资组合 A 最优权重:\n",
      "期望收益率: 25.03% (年化)\n",
      "期望波动率: 13.71% (年化)\n",
      "夏普比率: 1.46 (年化)\n",
      "\n",
      "投资组合 B 最优权重:\n",
      "期望收益率: 24.96% (年化)\n",
      "期望波动率: 13.47% (年化)\n",
      "夏普比率: 1.48 (年化)\n",
      "\n",
      "投资组合 C 最优权重:\n",
      "期望收益率: 25.17% (年化)\n",
      "期望波动率: 13.62% (年化)\n",
      "夏普比率: 1.48 (年化)\n",
      "\n",
      "最优夏普比率投资组合的归因结果:\n",
      "\n",
      "# Total Optimal Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373      0.022493      0.283866\n",
      "#  2   | Return Attribution         0.264376      0.019490      0.283866\n",
      "#  3   | Vol Attribution            0.007321     -0.000235      0.007086\n",
      "#  4   | Sharpe Ratio                      -             -      1.476269\n",
      "\n",
      "# A Optimal Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373      0.027229      0.288602\n",
      "#  2   | Return Attribution         0.264133      0.024469      0.288602\n",
      "#  3   | Vol Attribution            0.007290      0.000250      0.007539\n",
      "#  4   | Sharpe Ratio                      -             -      1.463484\n",
      "\n",
      "# B Optimal Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373     -0.003473      0.257900\n",
      "#  2   | Return Attribution         0.263159     -0.005259      0.257900\n",
      "#  3   | Vol Attribution            0.007350     -0.000150      0.007200\n",
      "#  4   | Sharpe Ratio                      -             -      1.483631\n",
      "\n",
      "# C Optimal Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | TotalReturn                0.261373      0.044523      0.305896\n",
      "#  2   | Return Attribution         0.265922      0.039974      0.305896\n",
      "#  3   | Vol Attribution            0.007250      0.000350      0.007600\n",
      "#  4   | Sharpe Ratio                      -             -      1.482658\n",
      "\n",
      "Comparison between Original and Optimal Portfolios:\n",
      "\n",
      "Total Portfolio Comparison:\n",
      "Metric               Original Portfolio Optimal Portfolio Difference\n",
      "-----------------------------------------------------------------\n",
      "Total Return                  20.47%          28.39%      7.91%\n",
      "Systematic Return             24.93%          26.44%      1.51%\n",
      "Idiosyncratic Return          -4.46%           1.95%      6.41%\n",
      "Portfolio Beta                 0.95           1.01      0.06\n",
      "\n",
      "Comparison for Portfolio A:\n",
      "Metric               Original Portfolio Optimal Portfolio Difference\n",
      "-----------------------------------------------------------------\n",
      "Total Return                  13.66%          28.86%     15.20%\n",
      "Systematic Return             25.29%          26.41%      1.12%\n",
      "Idiosyncratic Return         -11.63%           2.45%     14.07%\n",
      "Portfolio Beta                 0.97           1.01      0.04\n",
      "Optimal Sharpe Ratio              -           1.46          -\n",
      "\n",
      "Comparison for Portfolio B:\n",
      "Metric               Original Portfolio Optimal Portfolio Difference\n",
      "-----------------------------------------------------------------\n",
      "Total Return                  20.35%          25.79%      5.44%\n",
      "Systematic Return             24.07%          26.32%      2.24%\n",
      "Idiosyncratic Return          -3.72%          -0.53%      3.19%\n",
      "Portfolio Beta                 0.92           1.01      0.09\n",
      "Optimal Sharpe Ratio              -           1.48          -\n",
      "\n",
      "Comparison for Portfolio C:\n",
      "Metric               Original Portfolio Optimal Portfolio Difference\n",
      "-----------------------------------------------------------------\n",
      "Total Return                  28.12%          30.59%      2.47%\n",
      "Systematic Return             25.43%          26.59%      1.16%\n",
      "Idiosyncratic Return           2.68%           4.00%      1.32%\n",
      "Portfolio Beta                 0.97           1.02      0.04\n",
      "Optimal Sharpe Ratio              -           1.48          -\n",
      "\n",
      "Problem 5:\n",
      "\n",
      "\n",
      "# Total Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.012954      0.248419\n",
      "#  2   | Return Attribution         0.219995      0.028424      0.248419\n",
      "#  3   | Vol Attribution            0.006921      0.001956      0.007192\n",
      "\n",
      "# A Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.072257      0.189115\n",
      "#  2   | Return Attribution         0.217870     -0.028754      0.189115\n",
      "#  3   | Vol Attribution            0.006849      0.002976      0.007467\n",
      "\n",
      "# B Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373     -0.005503      0.255870\n",
      "#  2   | Return Attribution         0.218507      0.037363      0.255870\n",
      "#  3   | Vol Attribution            0.006877      0.002582      0.007346\n",
      "\n",
      "# C Portfolio Attribution\n",
      "# ----------------------------------------------------------------------\n",
      "#  Row | Value                           SPY         Alpha     Portfolio\n",
      "# ----------------------------------------------------------------------\n",
      "#  1   | Total Return               0.261373      0.044701      0.306074\n",
      "#  2   | Return Attribution         0.223905      0.082170      0.306074\n",
      "#  3   | Vol Attribution            0.007047      0.002484      0.007472\n",
      "\n",
      "=== Comparison of All Three Portfolio Strategies ===\n",
      "\n",
      "Total Portfolio Comparison:\n",
      "====================================================================================================\n",
      "Metric               Original        Optimal Sharpe  Risk Parity     OS vs Orig      RP vs Orig     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total Return                  20.47%          28.39%          24.84%           7.91%           4.37%\n",
      "Systematic Return             24.93%          26.44%          22.00%           1.51%          -2.93%\n",
      "Idiosyncratic Return          -4.46%           1.95%           2.84%           6.41%           7.30%\n",
      "Portfolio Beta                 0.95           1.01           0.84           0.06          -0.11\n",
      "\n",
      "Comparison for Portfolio A:\n",
      "====================================================================================================\n",
      "Metric               Original        Optimal Sharpe  Risk Parity     OS vs Orig      RP vs Orig     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total Return                  13.66%          28.86%          18.91%          15.20%           5.25%\n",
      "Systematic Return             25.29%          26.41%          21.79%           1.12%          -3.51%\n",
      "Idiosyncratic Return         -11.63%           2.45%          -2.88%          14.07%           8.75%\n",
      "Portfolio Beta                 0.97           1.01           0.83           0.04          -0.13\n",
      "VaR (95%)                      1.37%              -           1.20%              -          -0.17%\n",
      "ES (95%)                       1.85%              -           1.52%              -          -0.33%\n",
      "\n",
      "Comparison for Portfolio B:\n",
      "====================================================================================================\n",
      "Metric               Original        Optimal Sharpe  Risk Parity     OS vs Orig      RP vs Orig     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total Return                  20.35%          25.79%          25.59%           5.44%           5.23%\n",
      "Systematic Return             24.07%          26.32%          21.85%           2.24%          -2.22%\n",
      "Idiosyncratic Return          -3.72%          -0.53%           3.74%           3.19%           7.46%\n",
      "Portfolio Beta                 0.92           1.01           0.84           0.09          -0.08\n",
      "VaR (95%)                      1.24%              -           1.20%              -          -0.04%\n",
      "ES (95%)                       1.70%              -           1.51%              -          -0.19%\n",
      "\n",
      "Comparison for Portfolio C:\n",
      "====================================================================================================\n",
      "Metric               Original        Optimal Sharpe  Risk Parity     OS vs Orig      RP vs Orig     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Total Return                  28.12%          30.59%          30.61%           2.47%           2.49%\n",
      "Systematic Return             25.43%          26.59%          22.39%           1.16%          -3.04%\n",
      "Idiosyncratic Return           2.68%           4.00%           8.22%           1.32%           5.53%\n",
      "Portfolio Beta                 0.97           1.02           0.86           0.04          -0.12\n",
      "VaR (95%)                      1.52%              -           1.22%              -          -0.31%\n",
      "ES (95%)                       2.13%              -           1.54%              -          -0.59%\n",
      "\n",
      "=== Summary of Portfolio Strategy Comparison ===\n",
      "\n",
      "Key Findings:\n",
      "1. Best overall return: Risk Parity portfolio with 30.61%\n",
      "2. Lowest systematic risk (beta): Risk Parity portfolio with beta of 0.86\n",
      "3. Risk Parity approach reduced risk compared to original portfolio:\n",
      "   - Portfolio A: VaR changed by -12.49%, ES changed by -17.72%\n",
      "   - Portfolio B: VaR changed by -2.89%, ES changed by -11.03%\n",
      "   - Portfolio C: VaR changed by -20.20%, ES changed by -27.81%\n",
      "4. Best idiosyncratic return: Risk Parity portfolio with 8.22%\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
